{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs and scripts import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor, BaggingRegressor\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "# now you can import normally from ensemble\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ограничение на количество выводимых рядов\n",
    "#pd.set_option('display.max_rows', None)\n",
    "# ограничение на число столбцов\n",
    "#pd.set_option('display.max_columns', None)\n",
    "# ограничение на количество символов в записи\n",
    "#pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Strings in train:', train.shape[0])\n",
    "print('Strings in test:', test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape[1] - 1 == test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Exploratory Data Analysis. Data validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min, max, median, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train.loc[(train['HouseYear'] > 0)]\n",
    "for item in temp.columns:\n",
    "    if train[item].dtype in ['int64', 'float64']:\n",
    "        item_mean = temp[item].mean()\n",
    "        item_mode = temp[item].mode()[0]\n",
    "        item_median = temp[item].median()\n",
    "    else: \n",
    "        item_mean = None\n",
    "        item_mode = None\n",
    "        item_median = None\n",
    "    print(item, 'Min value: ', temp[item].min(), '\\n',\n",
    "          'Mean value: ', item_mean, '\\n',\n",
    "          'Mode value: ', item_mode, '\\n',\n",
    "          'Median value: ', item_median, '\\n',\n",
    "          'Max value: ', temp[item].max(),  '\\n',\n",
    "           np.unique,  '\\n', '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rounding and data correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round flat area\n",
    "train['Square'] = train['Square'].round(2)\n",
    "# round LifeSquare\n",
    "train['LifeSquare'] = train['LifeSquare'].round(2)\n",
    "# round KitchenSquare\n",
    "train['KitchenSquare'] = train['KitchenSquare'].round(2)\n",
    "# round Price\n",
    "train['Price'] = train['Price'].round(0)\n",
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing:\n",
    "    \"\"\"Correction of the possible wrong data\"\"\"\n",
    "    def __init__(self):\n",
    "        self.av_X = pd.DataFrame()\n",
    "    \n",
    "    def district_corr(self, X):\n",
    "        wrongDataIdx = (X['DistrictId'] == 0)\n",
    "        X.loc[wrongDataIdx, 'WrongDistr'] = 1\n",
    "        X.loc[wrongDataIdx, 'DistrictId'] = 9\n",
    "        \n",
    "        wrongDataIdx = (X['DistrictId'] >= 200)\n",
    "        X.loc[wrongDataIdx, 'WrongDistr'] = 1\n",
    "        X.loc[wrongDataIdx, 'DistrictId'] = X.loc[wrongDataIdx, 'DistrictId'].values - 200\n",
    "        \n",
    "        X.loc[(X['WrongDistr'].isnull()), 'WrongDistr'] = 0\n",
    "        return X\n",
    "    \n",
    "    def square_correction(self, X):\n",
    "        wrongDataIdx = (X['Square'] <= 10)\n",
    "        X.loc[wrongDataIdx, 'WrongSquare'] = 1\n",
    "        \n",
    "        wrongDataIdx = ((X['Square'] < 6) & (X['LifeSquare'] > X['Rooms'] * 15))\n",
    "        X.loc[wrongDataIdx, 'WrongSquare'] = 1\n",
    "        X.loc[wrongDataIdx, ['Square', 'LifeSquare']] = X.loc[wrongDataIdx, ['LifeSquare', 'Square']]\n",
    "        wrongDataIdx = (X['Square']>300)&(X['HouseYear']>1900)\n",
    "        X.loc[wrongDataIdx, 'WrongSquare'] = 1\n",
    "        X.loc[wrongDataIdx, ['Square']] = X.loc[wrongDataIdx, ['Square']].values/10\n",
    "        \n",
    "        X.loc[(X['WrongSquare'].isnull()), 'WrongSquare'] = 0\n",
    "        X['Square'] = X['Square'].round(1)\n",
    "        return X\n",
    "\n",
    "    def house_year_correction(self, X):\n",
    "        X.loc[(X['HouseYear'] > datetime.datetime.now().year), 'WrongHouseYear'] = 1\n",
    "        X.loc[(X['HouseYear'] <= datetime.datetime.now().year), 'WrongHouseYear'] = 0\n",
    "        if (X['HouseYear'] > datetime.datetime.now().year).any():\n",
    "            # if house year is in the following formate ?????1910, will be used 1910 for house year \n",
    "            wrongDataIdx = ((X['HouseYear'] > datetime.datetime.now().year) &\n",
    "                            (datetime.datetime.now().year >= X['HouseYear'] % 10000) &\n",
    "                            (X['HouseYear'] % 10000 >= 1910))\n",
    "\n",
    "            X.loc[wrongDataIdx, 'HouseYear'] = X.loc[wrongDataIdx, 'HouseYear'] % 10000\n",
    "            # if house year is in the following formate ?910, will be used 1910 for house year\n",
    "            wrongDataIdx = ((X['HouseYear'] > datetime.datetime.now().year) &\n",
    "                            (X['HouseYear'] // 10000 == 0) &\n",
    "                            (X['HouseYear'] % 1000 >= 900))\n",
    "\n",
    "            X.loc[wrongDataIdx, 'HouseYear'] = X.loc[wrongDataIdx, 'HouseYear'] % 1000 + 1000\n",
    "            # if house year is in the following formate ?010, will be used 2010 for house year \n",
    "            #X.loc[(X['HouseYear'] > datetime.datetime.now().year) & (X['HouseYear'] // 10000 == 0) & (X['HouseYear'] % 1000 <= datetime.datetime.now().year) & ((X['Floor'] <= 10) | (X['HouseFloor'] <= 10)), 'HouseYear'] = X.loc[(X['HouseYear'] > datetime.datetime.now().year) & (X['HouseYear'] // 10000 == 0) & (X['HouseYear'] % 1000 <= datetime.datetime.now().year) & ((X['Floor'] <= 10) | (X['HouseFloor'] <= 10)), 'HouseYear'] % 1000 + 1000\n",
    "            # nowadays, mainly houses with more than 10 floors are being built\n",
    "            wrongDataIdx = ((X['HouseYear'] > datetime.datetime.now().year) &\n",
    "                            (X['HouseYear'] // 10000 == 0) &\n",
    "                            (X['HouseYear'] % 1000 <= datetime.datetime.now().year) &\n",
    "                            ((X['Floor'] > 10) | (X['HouseFloor'] > 10)))\n",
    "\n",
    "            X.loc[wrongDataIdx, 'HouseYear'] = X.loc[wrongDataIdx, 'HouseYear'] % 1000 + 2000\n",
    "            # for any other cases will be used current year.\n",
    "            X.loc[(X['HouseYear'] > datetime.datetime.now().year), 'HouseYear'] = datetime.datetime.now().year\n",
    "        \n",
    "        wrongDataIdx = ((X['HouseFloor'] >= 30) & (X['HouseYear'] <= 1990))\n",
    "        corrDataIdx = ((X['HouseFloor'] >= 30) & (X['HouseYear'] >= 1990))\n",
    "        medianyear = round(X.loc[corrDataIdx, ['HouseYear']].median())\n",
    "        X.loc[wrongDataIdx, 'WrongHouseYear'] = 1\n",
    "        X.loc[wrongDataIdx, ['HouseYear']] = max(medianyear)\n",
    "        \n",
    "        wrongDataIdx = ((X['HouseFloor'] >= 24) & (X['HouseYear'] <= 1990))\n",
    "        corrDataIdx = ((X['HouseFloor'] >= 24) & (X['HouseYear'] >= 1990))\n",
    "        medianyear = round(X.loc[corrDataIdx, ['HouseYear']].median())\n",
    "        X.loc[wrongDataIdx, 'WrongHouseYear'] = 1\n",
    "        X.loc[wrongDataIdx, ['HouseYear']] = max(medianyear)\n",
    "        \n",
    "        wrongDataIdx = ((X['HouseFloor'] >= 18) & (X['HouseYear'] <= 1990))\n",
    "        corrDataIdx = ((X['HouseFloor'] >= 18) & (X['HouseYear'] >= 1990))\n",
    "        medianyear = round(X.loc[corrDataIdx, ['HouseYear']].median())\n",
    "        X.loc[wrongDataIdx, 'WrongHouseYear'] = 1\n",
    "        X.loc[wrongDataIdx, ['HouseYear']] = max(medianyear)\n",
    "        \n",
    "        wrongDataIdx = ((X['Floor'] >= 25) & (X['HouseYear'] <= 1990))\n",
    "        corrDataIdx = ((X['Floor'] >= 25) & (X['HouseYear'] >= 1990))\n",
    "        medianyear = round(X.loc[corrDataIdx, ['HouseYear']].median())\n",
    "        X.loc[wrongDataIdx, 'WrongHouseYear'] = 1\n",
    "        X.loc[wrongDataIdx, ['HouseYear']] = max(medianyear)\n",
    "        \n",
    "        wrongDataIdx = ((X['Floor'] >= 21) & (X['HouseYear'] <= 1990))\n",
    "        corrDataIdx = ((X['Floor'] >= 21) & (X['HouseYear'] >= 1990))\n",
    "        medianyear = round(X.loc[corrDataIdx, ['HouseYear']].median())\n",
    "        X.loc[wrongDataIdx, 'WrongHouseYear'] = 1\n",
    "        X.loc[wrongDataIdx, ['HouseYear']] = max(medianyear)\n",
    "        \n",
    "        wrongDataIdx = ((X['Floor'] >= 18) & (X['HouseYear'] <= 1990))\n",
    "        corrDataIdx = ((X['Floor'] >= 18) & (X['HouseYear'] >= 1990))\n",
    "        medianyear = round(X.loc[corrDataIdx, ['HouseYear']].median())\n",
    "        X.loc[wrongDataIdx, 'WrongHouseYear'] = 1\n",
    "        X.loc[wrongDataIdx, ['HouseYear']] = max(medianyear)\n",
    "        \n",
    "        wrongDataIdx = ((X['HouseFloor'] >= 18) & (X['HouseYear'] <= 1990))\n",
    "        X.loc[wrongDataIdx, 'WrongHouseYear'] = 1\n",
    "        X.loc[wrongDataIdx, ['HouseYear']] = max(medianyear)\n",
    "        X['HouseYear'] = X['HouseYear'].astype(int)\n",
    "        \n",
    "        X.loc[(X['WrongHouseYear'].isnull()), 'WrongHouseYear'] = 0\n",
    "        return X\n",
    "    \n",
    "    def number_of_rooms_correction(self, X):   \n",
    "        X.loc[(X['Rooms'] == 19), 'Rooms'] = 1\n",
    "        X.loc[(X['Rooms'] == 19), 'WrongRooms'] = 1\n",
    "        X.loc[(X['Rooms'] == 10) & (X['HouseYear'] >= 1992), 'Rooms'] = 1\n",
    "        X.loc[(X['Rooms'] == 10) & (X['HouseYear'] >= 1992), 'WrongRooms'] = 1\n",
    "        X.loc[(X['Rooms'] == 10) & (X['HouseYear'] < 1992), 'Rooms'] = 1\n",
    "        X.loc[(X['Rooms'] == 10) & (X['HouseYear'] < 1992), 'WrongRooms'] = 1\n",
    "        X.loc[(X['Rooms'] == 6) & (X['HouseYear'] < 1993), 'Rooms'] = 3\n",
    "        X.loc[(X['Rooms'] == 6) & (X['HouseYear'] < 1993), 'WrongRooms'] = 1\n",
    "        X.loc[(X['Rooms'] == 0) & (X['Square'] <= 24), 'SingleRoom'] = 1\n",
    "        wrongDataIdx = ((X['Square'] >= 20) & (X['Square'] < 37) & (X['Rooms'] == 0) & (X['HouseYear'] <= 1993))\n",
    "        X.loc[wrongDataIdx, 'WrongRooms'] = 1\n",
    "        X.loc[wrongDataIdx, ['Rooms']] = 1\n",
    "        \"\"\"wrongDataIdx = ((X['Square'] >= 20) & (X['Square'] < 37) & (X['Rooms'] > 1) & (X['HouseYear'] <= 1993))\n",
    "        X.loc[wrongDataIdx, 'WrongRooms'] = 1\n",
    "        X.loc[wrongDataIdx, ['Rooms']] = 1\"\"\"\n",
    "        \n",
    "        wrongDataIdx = ((X['Square'] >= 20) & (X['Square'] < 47) & (X['Rooms'] == 0) & (X['HouseYear'] > 1993))\n",
    "        X.loc[wrongDataIdx, 'WrongRooms'] = 1\n",
    "        X.loc[wrongDataIdx, ['Rooms']] = 1\n",
    "        \"\"\"wrongDataIdx = ((X['Square'] >= 20) & (X['Square'] < 47) & (X['Rooms'] > 1) & (X['HouseYear'] > 1993))\n",
    "        X.loc[wrongDataIdx, 'WrongRooms'] = 1\n",
    "        X.loc[wrongDataIdx, ['Rooms']] = 1\"\"\"\n",
    "        \n",
    "        wrongDataIdx = ((X['Square'] >= 38) & (X['Square'] < 52) & (X['Rooms'] == 0) & (X['HouseYear'] <= 1993))\n",
    "        X.loc[wrongDataIdx, 'WrongRooms'] = 1\n",
    "        X.loc[wrongDataIdx, ['Rooms']] = 2\n",
    "        \"\"\"wrongDataIdx = ((X['Square'] >= 38) & (X['Square'] < 52) & (X['Rooms'] != 2) & (X['HouseYear'] <= 1993))\n",
    "        X.loc[wrongDataIdx, 'WrongRooms'] = 1\n",
    "        X.loc[wrongDataIdx, ['Rooms']] = 2\"\"\"\n",
    "        \n",
    "        wrongDataIdx = ((X['Square'] >= 47) & (X['Square'] < 80) & (X['Rooms'] == 0) & (X['HouseYear'] > 1993))\n",
    "        X.loc[wrongDataIdx, 'WrongRooms'] = 1\n",
    "        X.loc[wrongDataIdx, ['Rooms']] = 2\n",
    "        \"\"\"wrongDataIdx = ((X['Square'] >= 47) & (X['Square'] < 80) & (X['Rooms'] != 2) & (X['Rooms'] != 3) & (X['HouseYear'] > 1993))\n",
    "        X.loc[wrongDataIdx, 'WrongRooms'] = 1\n",
    "        X.loc[wrongDataIdx, ['Rooms']] = 2\"\"\"\n",
    "        \n",
    "        wrongDataIdx = ((X['Square'] >= 52) & (X['Square'] < 80) & (X['Rooms'] == 0) & (X['HouseYear'] <= 1993))\n",
    "        X.loc[wrongDataIdx, 'WrongRooms'] = 1\n",
    "        X.loc[wrongDataIdx, ['Rooms']] = 3\n",
    "        \"\"\"wrongDataIdx = ((X['Square'] >= 52) & (X['Square'] < 80) & (X['Rooms'] != 2) & (X['HouseYear'] <= 1993))\n",
    "        X.loc[wrongDataIdx, 'WrongRooms'] = 1\n",
    "        X.loc[wrongDataIdx, ['Rooms']] = 3\"\"\"\n",
    "        \n",
    "        wrongDataIdx = ((X['Square'] >= 65) & (X['Square'] < 120) & (X['Rooms'] == 0) & (X['HouseYear'] > 1993))\n",
    "        X.loc[wrongDataIdx, 'WrongRooms'] = 1\n",
    "        X.loc[wrongDataIdx, ['Rooms']] = 3\n",
    "        \"\"\"wrongDataIdx = ((X['Square'] >= 65) & (X['Square'] < 120) & (X['Rooms'] != 3) & (X['Rooms'] != 4) & (X['HouseYear'] > 1993))\n",
    "        X.loc[wrongDataIdx, 'WrongRooms'] = 1\n",
    "        X.loc[wrongDataIdx, ['Rooms']] = 3\"\"\"\n",
    "        \n",
    "        X['Rooms'] = X['Rooms'].astype(int)\n",
    "        X.loc[(X['Rooms'] == 0), 'Rooms'] = 1\n",
    "        \n",
    "        X.loc[(X['WrongRooms'].isnull()), 'WrongRooms'] = 0\n",
    "        X.loc[(X['SingleRoom'].isnull()), 'SingleRoom'] = 0\n",
    "        return X\n",
    "    \n",
    "    def house_floor_correction(self, X):\n",
    "        wrongDataIdx = ((X['HouseFloor'] == 117))\n",
    "        X.loc[wrongDataIdx, 'WrongHouseFloor'] = 1\n",
    "        X.loc[wrongDataIdx, ['HouseFloor']] = 17\n",
    "        \n",
    "        wrongDataIdx = ((X['HouseFloor'] == 99))\n",
    "        X.loc[wrongDataIdx, 'WrongHouseFloor'] = 1\n",
    "        X.loc[wrongDataIdx, ['HouseFloor']] = 9\n",
    "        \n",
    "        wrongDataIdx = ((X['HouseFloor'] < X['Floor']) & (X['Floor'] <= 17) & (X['HouseYear'] < 1990))\n",
    "        X.loc[wrongDataIdx, 'WrongHouseFloor'] = 1\n",
    "        X.loc[wrongDataIdx, ['Floor','HouseFloor']] = X.loc[wrongDataIdx, ['HouseFloor','Floor']].values\n",
    "        \n",
    "        wrongDataIdx = ((X['HouseFloor'] < X['Floor']) & (X['HouseYear'] >= 1990))\n",
    "        X.loc[wrongDataIdx, 'WrongHouseFloor'] = 1\n",
    "        X.loc[wrongDataIdx, ['Floor','HouseFloor']] = X.loc[wrongDataIdx, ['HouseFloor','Floor']].values\n",
    "        step = 1\n",
    "        for hyear in range(1900,2020,2):\n",
    "            wrongDataIdx = ((X['HouseFloor'] < 3) & (X['HouseYear'] >= hyear - step) & (X['HouseYear'] <= hyear + step))\n",
    "            corrDataIdx = ((X['HouseFloor'] >= 3) & (X['HouseYear'] >= hyear - step) & (X['HouseYear'] <= hyear + step))\n",
    "            if ((X.loc[wrongDataIdx, 'HouseFloor'].count() != 0) & (X.loc[corrDataIdx, 'HouseFloor'].count() > 3)):\n",
    "                medianhfloor = X.loc[corrDataIdx, ['HouseFloor']].median()\n",
    "                if medianhfloor.isnull().any():\n",
    "                    corrDataIdx = ((X['HouseFloor'] >= 3) & (X['HouseYear'] >= hyear - step - 5) & (X['HouseYear'] <= hyear + step + 5))\n",
    "                    medianhfloor = X.loc[corrDataIdx, ['HouseFloor']].median()\n",
    "                X.loc[wrongDataIdx, 'HouseFloor'] = 1\n",
    "                X.loc[wrongDataIdx, ['HouseFloor']] = max(medianhfloor)\n",
    "        X['HouseFloor'] = X['HouseFloor'].round().astype(int)\n",
    "        X.loc[(X['WrongHouseFloor'].isnull()), 'WrongHouseFloor'] = 0\n",
    "        return X\n",
    "    \n",
    "    def floor_correction(self, X):\n",
    "        X.loc[(X['Floor'] == 0) & (X['HouseYear'] < 1945), 'Floor'] = 1\n",
    "        X.loc[(X['Floor'] == 0) & (X['HouseYear'] < 1945), 'WrongFloor'] = 1\n",
    "        X.loc[(X['Floor'] == 0) & (X['HouseYear'] > 1944), 'Floor'] = 9\n",
    "        X.loc[(X['Floor'] == 0) & (X['HouseYear'] > 1944), 'WrongFloor'] = 1\n",
    "   \n",
    "        wrongDataIdx = ((X['Floor'] > X['HouseFloor']))\n",
    "        # [a,b] = [b,a]\n",
    "        X.loc[wrongDataIdx, ['Floor','HouseFloor']] = X.loc[wrongDataIdx, ['HouseFloor','Floor']].values\n",
    "        X.loc[wrongDataIdx, 'WrongFloor'] = 1\n",
    "        X.loc[(X['Floor'] == 0), 'Floor'] = 1\n",
    "        X.loc[(X['Floor'] == 0), 'WrongFloor'] = 1\n",
    "        X['Floor'] = X['Floor'].round().astype(int)\n",
    "        X.loc[(X['WrongFloor'].isnull()), 'WrongFloor'] = 0\n",
    "        return X\n",
    "    \n",
    "    def life_square_correction(self, X):\n",
    "        wrongDataIdx = (X['LifeSquare'] < 7)\n",
    "        X.loc[wrongDataIdx, 'WrongLifeSquare'] = 1\n",
    "        step = 14\n",
    "        for numrooms in range(1,6):\n",
    "            for houseyearstep in range(1900,2020,12):\n",
    "                wrongDataIdx = ((X['LifeSquare'].isnull()) & (X['Rooms'] == numrooms) & (X['HouseYear'] >= houseyearstep - step) & (X['HouseYear'] < houseyearstep))\n",
    "                corrDataIdx = ((X['Square'] > 20) & (X['LifeSquare'] > 6) & (X['LifeSquare'] < X['Square'] - 7) &(X['Rooms'] == numrooms) & (X['HouseYear'] >= houseyearstep - step) & (X['HouseYear'] < houseyearstep))\n",
    "                X.loc[wrongDataIdx, 'WrongLifeSquare'] = 1\n",
    "                squarediff = (X.loc[corrDataIdx, 'Square'].median() - X.loc[corrDataIdx, 'LifeSquare'].median())\n",
    "                X.loc[wrongDataIdx, 'LifeSquare'] = X.loc[wrongDataIdx, 'Square'] - squarediff\n",
    "                wrongDataIdx = ((X['LifeSquare'] < 6) & (X['Rooms'] == numrooms) & (X['HouseYear'] >= houseyearstep - step) & (X['HouseYear'] < houseyearstep))\n",
    "                X.loc[wrongDataIdx, 'WrongLifeSquare'] = 1\n",
    "                X.loc[wrongDataIdx, 'LifeSquare'] = X.loc[wrongDataIdx, 'Square'] - squarediff\n",
    "                wrongDataIdx = ((X['Square'] > 20) & (X['LifeSquare'] > X['Square'] - 8) & (X['Rooms'] == numrooms) & (X['HouseYear'] >= houseyearstep - step) & (X['HouseYear'] < houseyearstep))\n",
    "                X.loc[wrongDataIdx, 'WrongLifeSquare'] = 1\n",
    "                X.loc[wrongDataIdx, 'LifeSquare'] = X.loc[wrongDataIdx, 'Square'] - squarediff\n",
    "                wrongDataIdx = ((X['Square'] > 20) & (X['LifeSquare']/X['Square'] > 0.87) & (X['Rooms'] == numrooms) & (X['HouseYear'] >= houseyearstep - step) & (X['HouseYear'] < houseyearstep))\n",
    "                X.loc[wrongDataIdx, 'WrongLifeSquare'] = 1\n",
    "                X.loc[wrongDataIdx, 'LifeSquare'] = X.loc[wrongDataIdx, 'Square'] - squarediff\n",
    "                wrongDataIdx = ((X['Square'] > 20) & (X['LifeSquare']/X['Square'] < 0.5) & (X['Rooms'] == numrooms) & (X['HouseYear'] >= houseyearstep - step) & (X['HouseYear'] < houseyearstep))\n",
    "                X.loc[wrongDataIdx, 'WrongLifeSquare'] = 1\n",
    "                X.loc[wrongDataIdx, 'LifeSquare'] = X.loc[wrongDataIdx, 'Square'] - squarediff\n",
    "        wrongDataIdx = ((X['LifeSquare'].isnull()))\n",
    "        corrDataIdx = ((X['Square'] > 20) & (X['LifeSquare'] > 6) & (X['LifeSquare'] < X['Square'] - 7))\n",
    "        squarediff = (X.loc[corrDataIdx, 'Square'].median() - X.loc[corrDataIdx, 'LifeSquare'].median())\n",
    "        X.loc[wrongDataIdx, 'LifeSquare'] = X.loc[wrongDataIdx, 'Square'] - squarediff\n",
    "        X.loc[wrongDataIdx, 'WrongLifeSquare'] = 1\n",
    "       \n",
    "        wrongDataIdx = (X['LifeSquare']/X['Square'] > 0.87)\n",
    "        corrDataIdx = ((X['Square'] > 20) & (X['LifeSquare'] > 6) & (X['LifeSquare'] < X['Square'] - 7) & (X['LifeSquare']/X['Square'] < 0.87))\n",
    "        squarediff = (X.loc[corrDataIdx, 'Square'].median() - X.loc[corrDataIdx, 'LifeSquare'].median())\n",
    "        X.loc[wrongDataIdx, 'LifeSquare'] = X.loc[wrongDataIdx, 'Square'] - squarediff\n",
    "        X.loc[wrongDataIdx, 'WrongLifeSquare'] = 1\n",
    "        \n",
    "        wrongDataIdx = (X['LifeSquare'] <= 0)\n",
    "        X.loc[wrongDataIdx, 'LifeSquare'] = X.loc[wrongDataIdx, 'Square']\n",
    "        X.loc[wrongDataIdx, 'WrongLifeSquare'] = 1\n",
    "        X.loc[(X['WrongLifeSquare'].isnull()), 'WrongLifeSquare'] = 0\n",
    "        X['LifeSquare'] = X['LifeSquare'].round(1)\n",
    "        return X\n",
    "        \n",
    "    def kitchen_square_correction(self, X):\n",
    "        step = 7\n",
    "        for numrooms in range(1,6):\n",
    "            for houseyearstep in range(1900,2020,10):\n",
    "                if houseyearstep <= 1993:\n",
    "                    wrongDataIdx = ((X['KitchenSquare']/X['Square'] >= 0.3) | (X['KitchenSquare'] < 3))\n",
    "                    corrDataIdx = ((X['KitchenSquare']/X['Square'] < 0.3) & (X['KitchenSquare'] > 3))\n",
    "                elif houseyearstep > 1993:\n",
    "                    wrongDataIdx = ((X['KitchenSquare']/X['Square'] >= 0.43) | (X['KitchenSquare'] < 3))\n",
    "                    corrDataIdx = ((X['KitchenSquare']/X['Square'] < 0.43) & (X['KitchenSquare'] > 3))\n",
    "                wrongDataIdx1 = ((X['Rooms'] == numrooms) & (X['HouseYear'] >= houseyearstep - step) & (X['HouseYear'] < houseyearstep + step))\n",
    "                X.loc[wrongDataIdx & wrongDataIdx1, 'KitchenSquare'] = X.loc[corrDataIdx & wrongDataIdx1, 'KitchenSquare'].median()\n",
    "                X.loc[wrongDataIdx & wrongDataIdx1, 'WrongKitchenSquare'] = 1\n",
    "                if houseyearstep <= 1993:\n",
    "                    wrongDataIdx = ((X['KitchenSquare'] < 3))\n",
    "                    corrDataIdx = ((X['KitchenSquare']/X['Square'] < 0.3) & (X['KitchenSquare'] > 3))\n",
    "                elif houseyearstep > 1993:\n",
    "                    wrongDataIdx = ((X['KitchenSquare'] < 3))\n",
    "                    corrDataIdx = ((X['KitchenSquare']/X['Square'] < 0.43) & (X['KitchenSquare'] > 3))\n",
    "                wrongDataIdx1 = ((X['Rooms'] == numrooms) & (X['HouseYear'] >= houseyearstep - step) & (X['HouseYear'] < houseyearstep + step))\n",
    "                X.loc[wrongDataIdx & wrongDataIdx1, 'KitchenSquare'] = X.loc[corrDataIdx & wrongDataIdx1, 'KitchenSquare'].median()\n",
    "                X.loc[wrongDataIdx & wrongDataIdx1, 'WrongKitchenSquare'] = 1\n",
    "        wrongDataIdx = (X['KitchenSquare'].isnull())\n",
    "        X.loc[wrongDataIdx, 'KitchenSquare'] = (X.loc[wrongDataIdx, 'Square'] - X.loc[wrongDataIdx, 'LifeSquare']) * 0.6\n",
    "        X.loc[(X['WrongKitchenSquare'].isnull()), 'WrongKitchenSquare'] = 0\n",
    "        return X\n",
    "    \n",
    "    def healthcare_1_corr(self, X):\n",
    "        distmin = int(min(X['DistrictId']))\n",
    "        distmax = int(max(X['DistrictId']))\n",
    "        for dist in range(distmin, distmax):\n",
    "            for hyear in range(1900, 2020):\n",
    "                wrongDataIdx = ((X['DistrictId'] == dist) & (X['HouseYear'] == hyear) & X['Healthcare_1'].isnull())\n",
    "                corrDataIdx = ((X['DistrictId'] == dist) & (X['HouseYear'] == hyear))\n",
    "                X.loc[wrongDataIdx, 'Healthcare_1'] = X.loc[corrDataIdx, 'Healthcare_1'].median()\n",
    "            wrongDataIdx = ((X['DistrictId'] == dist) & X['Healthcare_1'].isnull())\n",
    "            corrDataIdx = ((X['DistrictId'] == dist))\n",
    "            X.loc[wrongDataIdx, 'Healthcare_1'] = X.loc[corrDataIdx, 'Healthcare_1'].median()\n",
    "        wrongDataIdx = (X['Healthcare_1'].isnull())\n",
    "        X.loc[wrongDataIdx, 'Healthcare_1'] = X['Healthcare_1'].median()\n",
    "        return X\n",
    "    \n",
    "    def str_val_to_num(self, X):\n",
    "        str_to_numbers = {'A': 0, 'B': 1}\n",
    "        X['Ecology_2'] = X['Ecology_2'].replace(str_to_numbers)\n",
    "        X['Ecology_3'] = X['Ecology_3'].replace(str_to_numbers)\n",
    "        X['Shops_2'] = X['Shops_2'].replace(str_to_numbers)\n",
    "        return X\n",
    "    \n",
    "    def null_elements_correction(self, X):\n",
    "        self.av_X = pd.DataFrame(data = None, index = list('1'), columns = X.columns)\n",
    "        for item in X.columns:\n",
    "            if self.av_X[item].isnull().any():\n",
    "                if not('Wrong' in item):\n",
    "                    self.av_X.loc[self.av_X[item].isnull(), item] = X[item].median()\n",
    "                    #self.av_X.iloc[0][item] = X[item].median()\n",
    "                    self.av_X[item] = self.av_X[item].astype(X[item].dtypes)\n",
    "            if (X[item].isnull().any()) & (not('Wrong' in item)):\n",
    "                X.loc[(X[item].isnull()), item] = self.av_X.iloc[0][item]\n",
    "            else:\n",
    "                X.loc[(X[item].isnull()), item] = 0\n",
    "            #X.loc[(X[item].isnull()) & (item == 'HouseYear'), item] = datetime.datetime.now().year\n",
    "        #print('NaN elements: \\n', X.isnull().sum())\n",
    "        return X\n",
    "    \n",
    "    def data_correction(self, Y):\n",
    "        Y['Square'] = Y['Square'].round(2)\n",
    "        Y['LifeSquare'] = Y['LifeSquare'].round(2)\n",
    "        Y['KitchenSquare'] = Y['KitchenSquare'].round(2)\n",
    "        if 'Price' in Y.columns:\n",
    "            Y['Price'] = Y['Price'].round(2)\n",
    "        Y = self.district_corr(Y)\n",
    "        Y = self.square_correction(Y)\n",
    "        Y = self.house_floor_correction(Y)\n",
    "        Y = self.house_year_correction(Y)\n",
    "        Y = self.number_of_rooms_correction(Y)\n",
    "        Y = self.floor_correction(Y)\n",
    "        Y = self.life_square_correction(Y)\n",
    "        Y = self.kitchen_square_correction(Y)\n",
    "        Y = self.healthcare_1_corr(Y)\n",
    "        Y = self.str_val_to_num(Y)\n",
    "        Y = self.null_elements_correction(Y)\n",
    "        Y['Id'] = Y['Id'].astype(str)\n",
    "        return Y \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessing()\n",
    "#train = preprocessor.data_correction(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min, max, median, etc. after correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train.columns:\n",
    "    if train[item].dtype in ['int64', 'float64']:\n",
    "        item_mean = train[item].mean()\n",
    "        item_mode = train[item].mode()[0]\n",
    "        item_median = train[item].median()\n",
    "    else: item_mean = None\n",
    "    print(item, 'Min value: ', train[item].min(), '\\n',\n",
    "          'Mean value: ', item_mean, '\\n',\n",
    "          'Mode value: ', item_mode, '\\n',\n",
    "          'Median value: ', item_median, '\\n',\n",
    "          'Max value: ', train[item].max(),  '\\n',\n",
    "           np.unique,  '\\n', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"sq = train.groupby('Square')['Square'].count()\n",
    "sq.sort_values()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"train.loc[ train['Square'] == 409, ['HouseYear', 'Square', 'Rooms', 'Floor']]\n",
    "for item in train['Square']:\n",
    "    sq = train.groupby('Square')['Square'].count()\n",
    "    if 0 < sq[item] < 2:\n",
    "        print(train.loc[(train['Square'] == item) & (train['Square'] < 27), ['HouseYear', 'Square', 'LifeSquare', 'KitchenSquare', 'Rooms', 'HouseFloor','Floor', 'DistrictId']])\n",
    "    \n",
    "#train = train.merge(sq, on = 'Square', how = 'left')\n",
    "#train.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "dataindx = (train['Square'] >= 27) & (train['HouseYear'] <= 2020) & (train['DistrictId'] >= 1)\n",
    "sns.scatterplot(x = train.loc[dataindx, 'HouseYear'], y = train.loc[dataindx, 'DistrictId'])\n",
    "plt.grid(b = True, which = 'both')\n",
    "plt.minorticks_on\n",
    "plt.show()\n",
    "train.loc[dataindx, 'HouseYear'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train.columns:\n",
    "    print(item, ' -- ', 'Unique values:', pd.unique(train[item]), '\\n', '\\n', pd.value_counts((train[item])), '\\n\\n\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['HouseYear'], bins = 2022-1900, range = (1900,2022), log = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.loc[train['HouseYear'] ==1977]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking of empty elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is plot for price per sq.m from rooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train['Rooms'], train['Price']/train['Square'])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_num = 15\n",
    "price_per_area = 10000\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 12), tight_layout=True)\n",
    "axs[0,0].hist((train['Price']/train['Square']).loc[(train['Rooms'] == 1) & ((train['Price']/train['Square']) < price_per_area)], bins = bins_num, density = True, alpha = 0.4, color = 'orange')\n",
    "axs[0,0].hist((train['Price']/train['Square']).loc[(train['Rooms'] == 2) & ((train['Price']/train['Square']) < price_per_area)], bins = bins_num, density = True, alpha = 0.4, color = 'yellow')\n",
    "axs[0,0].hist((train['Price']/train['Square']).loc[(train['Rooms'] == 3) & ((train['Price']/train['Square']) < price_per_area)], bins = bins_num, density = True, alpha = 0.4, color = 'green')\n",
    "axs[0,0].hist((train['Price']/train['Square']).loc[(train['Rooms'] == 4) & ((train['Price']/train['Square']) < price_per_area)], bins = bins_num, density = True, alpha = 0.4, color = 'grey')\n",
    "axs[0,0].hist((train['Price']/train['Square']).loc[(train['Rooms'] == 5) & ((train['Price']/train['Square']) < price_per_area)], bins = bins_num, density = True, alpha = 0.4, color = 'blue')\n",
    "axs[0,0].legend(labels=['Rooms = 1', 'Rooms = 2', 'Rooms = 3', 'Rooms = 4', 'Rooms = 5', 'Rooms = 6'])\n",
    "axs[0,1].hist((train['Price']/train['Square']).loc[(train['Rooms'] == 1) & ((train['Price']/train['Square']) < price_per_area)], bins = bins_num, density = True, alpha = 0.4, color = 'orange')\n",
    "axs[0,1].axvline((train['Price']/train['Square']).loc[(train['Rooms'] == 1) & ((train['Price']/train['Square']) < price_per_area)].mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "axs[1,0].hist((train['Price']/train['Square']).loc[(train['Rooms'] == 2) & ((train['Price']/train['Square']) < price_per_area)], bins = bins_num, density = True, alpha = 0.4, color = 'yellow')\n",
    "axs[1,0].axvline((train['Price']/train['Square']).loc[(train['Rooms'] == 2) & ((train['Price']/train['Square']) < price_per_area)].mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "axs[1,1].hist((train['Price']/train['Square']).loc[(train['Rooms'] == 3) & ((train['Price']/train['Square']) < price_per_area)], bins = bins_num, density = True, alpha = 0.4, color = 'green')\n",
    "axs[1,1].axvline((train['Price']/train['Square']).loc[(train['Rooms'] == 3) & ((train['Price']/train['Square']) < price_per_area)].mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "axs[2,0].hist((train['Price']/train['Square']).loc[(train['Rooms'] == 4) & ((train['Price']/train['Square']) < price_per_area)], bins = bins_num, density = True, alpha = 0.4, color = 'grey')\n",
    "axs[2,0].axvline((train['Price']/train['Square']).loc[(train['Rooms'] == 4) & ((train['Price']/train['Square']) < price_per_area)].mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "axs[2,1].hist((train['Price']/train['Square']).loc[(train['Rooms'] == 5) & ((train['Price']/train['Square']) < price_per_area)], bins = bins_num, density = True, alpha = 0.4, color = 'blue')\n",
    "axs[2,1].axvline((train['Price']/train['Square']).loc[(train['Rooms'] == 5) & ((train['Price']/train['Square']) < price_per_area)].mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "axs[0,0].set_xlabel('Price per m^2')\n",
    "axs[0,1].set_xlabel('Price per m^2')\n",
    "axs[1,0].set_xlabel('Price per m^2')\n",
    "axs[1,1].set_xlabel('Price per m^2')\n",
    "axs[2,0].set_xlabel('Price per m^2')\n",
    "axs[2,1].set_xlabel('Price per m^2')\n",
    "axs[0,0].grid(True)\n",
    "axs[0,1].grid(True)\n",
    "axs[1,0].grid(True)\n",
    "axs[1,1].grid(True)\n",
    "axs[2,0].grid(True)\n",
    "axs[2,1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axs[0].hist2d(train['Rooms'], train['Price'], bins=(5, 80), norm = colors.LogNorm())\n",
    "axs[1].hist2d(train['Rooms'], train['Price']/train['Square'], bins=(5, 80), norm = colors.LogNorm())\n",
    "axs[0].grid(True)\n",
    "axs[1].grid(True)\n",
    "axs[0].set_xlabel('Rooms')\n",
    "axs[0].set_title('Price')\n",
    "axs[0].set_ylabel('Price')\n",
    "axs[1].set_xlabel('Rooms')\n",
    "axs[1].set_title('Price per square')\n",
    "axs[1].set_ylabel('Price per m^2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5), sharex=True, sharey=True, tight_layout=True)\n",
    "axs[0].hist2d(train['Floor'], train['Price']/train['Square'], bins=(6, 80), norm = colors.LogNorm())\n",
    "axs[1].hist2d(train['HouseFloor'], train['Price']/train['Square'], bins=(6, 80), norm = colors.LogNorm())\n",
    "axs[0].grid(True)\n",
    "axs[1].grid(True)\n",
    "axs[0].set_xlabel('Floor')\n",
    "axs[0].set_title('Price per m^2 from floor')\n",
    "axs[0].set_ylabel('Price per m^2')\n",
    "axs[1].set_xlabel('House floor')\n",
    "axs[1].set_title('Price per square from house floor')\n",
    "axs[1].set_ylabel('Price per m^2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axs[0].hist2d(train['HouseYear'], train['Price'], bins=(6, 80), norm = colors.LogNorm())\n",
    "axs[1].hist2d(train['HouseYear'], train['Price']/train['Square'], bins=(6, 80), norm = colors.LogNorm())\n",
    "axs[0].grid(True)\n",
    "axs[1].grid(True)\n",
    "axs[0].set_xlabel('HouseYear')\n",
    "axs[0].set_title('Price')\n",
    "axs[0].set_ylabel('Price')\n",
    "axs[1].set_xlabel('HouseYear')\n",
    "axs[1].set_title('Price per square')\n",
    "axs[1].set_ylabel('Price per m^2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axs[0].hist2d(train['DistrictId'], train['Price'], bins=(6, 80), norm = colors.LogNorm())\n",
    "axs[1].hist2d(train['DistrictId'], train['Price']/train['Square'], bins=(6, 80), norm = colors.LogNorm())\n",
    "axs[0].grid(True)\n",
    "axs[1].grid(True)\n",
    "axs[0].set_xlabel('DistrictId')\n",
    "axs[0].set_title('Price')\n",
    "axs[0].set_ylabel('Price')\n",
    "axs[1].set_xlabel('DistrictId')\n",
    "axs[1].set_title('Price per square')\n",
    "axs[1].set_ylabel('Price per m^2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Id and DistrictId types to string type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Id'] = train['Id'].astype(str)\n",
    "train['DistrictId'] = train['DistrictId'].astype(str)\n",
    "\n",
    "train.select_dtypes(include='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. New numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_numbers = {'A': 0, 'B': 1}\n",
    "if train['Ecology_2'].dtype == 'object':\n",
    "    train['Ecology_2'] = train['Ecology_2'].replace(str_to_numbers)\n",
    "if train['Ecology_3'].dtype == 'object':\n",
    "    train['Ecology_3'] = train['Ecology_3'].replace(str_to_numbers)\n",
    "if train['Shops_2'].dtype == 'object':\n",
    "    train['Shops_2'] = train['Shops_2'].replace(str_to_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "District is close to the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_location = train.groupby('DistrictId')['HouseYear'].median().reset_index()\\\n",
    ".rename(columns={'index':'DistrictId', 'HouseYear':'DistrictLocation'})\n",
    "district_location['DistrictLocation'] = district_location['DistrictLocation'].astype(int)\n",
    "#print(district_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(district_location['DistrictLocation'], bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(district_location, on='DistrictId', how='left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "District have good planting of greenery (lover houses floor - more big trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_house_floor = train.groupby('DistrictId')['HouseFloor'].median().reset_index()\\\n",
    ".rename(columns={'index':'DistrictId', 'HouseFloor':'AvHouseFloor'})\n",
    "average_house_floor['AvHouseFloor'] = average_house_floor['AvHouseFloor'].astype(int)\n",
    "#print(average_house_floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(average_house_floor['AvHouseFloor'], bins = 60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(average_house_floor, on='DistrictId', how='left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_flats = train['DistrictId'].value_counts().reset_index()\\\n",
    "                    .rename(columns={'index':'DistrictId', 'DistrictId':'NumberOfFlats'})\n",
    "#number_of_flats['NumberOfFlats'] = number_of_flats['NumberOfFlats'].astype(int)\n",
    "#print(number_of_flats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(number_of_flats, on='DistrictId', how='left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "District have some new houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_building_year = train.groupby('DistrictId')['HouseYear'].mean().reset_index()\\\n",
    ".rename(columns={'index':'DistrictId', 'HouseYear':'MeanBuildingYear'})\n",
    "mean_building_year['MeanBuildingYear'] = mean_building_year['MeanBuildingYear'].astype(int)\n",
    "#print(mean_building_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mean_building_year['MeanBuildingYear'], bins = 2020-1920, range =(1920,2020) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(mean_building_year, on='DistrictId', how='left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "District population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_population = train.groupby('DistrictId')['Rooms'].mean().reset_index()\\\n",
    ".rename(columns={'index':'DistrictId', 'Rooms':'DistrictPopulation'})\n",
    "number_of_flats = train['DistrictId'].value_counts().reset_index()\\\n",
    "                    .rename(columns={'index':'DistrictId', 'DistrictId':'NumberOfFlats'})\n",
    "district_population = district_population.merge(number_of_flats, on='DistrictId', how='left')\n",
    "district_population['DistrictAvPopulation'] = district_population[\"DistrictPopulation\"]/district_population[\"NumberOfFlats\"]\n",
    "district_population = district_population.drop(['NumberOfFlats', 'DistrictPopulation'], axis = 1)\n",
    "#print(district_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(district_population['DistrictAvPopulation'], bins = 60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(district_population, on='DistrictId', how='left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average meter price by district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_av_meter_price = train.groupby('DistrictId')['Price'].mean().reset_index()\\\n",
    ".rename(columns={'index':'DistrictId'})\n",
    "district_av_square = train.groupby('DistrictId')['Square'].mean().reset_index()\\\n",
    "                    .rename(columns={'index':'DistrictId'})\n",
    "district_av_meter_price = district_av_meter_price.merge(district_av_square, on='DistrictId', how='left')\n",
    "district_av_meter_price['DistrictAvMeterPrice'] = district_av_meter_price[\"Price\"]/district_av_meter_price[\"Square\"]\n",
    "district_av_meter_price = district_av_meter_price.drop(['Price', 'Square'], axis = 1)\n",
    "#print(district_av_meter_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(district_av_meter_price['DistrictAvMeterPrice'], bins = 60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(district_av_meter_price, on='DistrictId', how='left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average price of sq meter for rooms number in district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['RoomsMeterPrice'] = train['Price']/train['Square']\n",
    "rooms_av_meter_price = train.groupby(['DistrictId','Rooms'])['RoomsMeterPrice'].mean().reset_index()\\\n",
    "                    .rename(columns={'index':'Rooms', 'RoomsMeterPrice':'RoomsAvMeterPrice'})\n",
    "rooms_av_meter_price.head(10)\n",
    "train = train.drop(columns=['RoomsMeterPrice'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(rooms_av_meter_price, how='left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average price of sq meter for floor number in district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FloorMeterPrice'] = train['Price']/train['Floor']/train['Square']\n",
    "floor_meter_price = train.groupby(['DistrictId','Floor'])['FloorMeterPrice'].mean().reset_index()\\\n",
    "                    .rename(columns={'index':'Rooms', 'FloorMeterPrice':'FloorAvMeterPrice'})\n",
    "floor_meter_price.head()\n",
    "#train = train.drop(columns=['RoomsMeterPrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(floor_meter_price['FloorAvMeterPrice'], bins = 60, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(floor_meter_price, how = 'left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(round(train['Square']/10))['Price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGeneration:\n",
    "    def __init__(self, Y):\n",
    "        self.y = Y\n",
    "        self.square_av_meter_price_df = None\n",
    "        self.av_meter_price_df = None\n",
    "        self.district_av_meter_price_df = None\n",
    "        self.district_house_floor_av_meter_price_df = None\n",
    "        self.rooms_av_meter_price_df = None\n",
    "        self.district_rooms_av_meter_price_df = None\n",
    "        self.district_house_year_rooms_av_meter_price_df = None\n",
    "        self.house_year_rooms_av_meter_price_df = None\n",
    "        self.district_house_floor_rooms_av_meter_price_df = None\n",
    "        self.district_kitchen_square_rooms_av_meter_price_df = None\n",
    "        self.district_life_square_rooms_av_meter_price_df = None\n",
    "        self.flat_av_meter_price_df = None\n",
    "        self.floor_meter_price_df = None\n",
    "        self.district_location_df = None\n",
    "        self.average_house_floor_df = None\n",
    "        self.number_of_flats_df = None\n",
    "        self.mean_building_year_df = None\n",
    "        self.district_population_df = None\n",
    "        self.district_planting_of_greenery_df = None\n",
    "        self.ecology_df = None\n",
    "        self.district_house_year_kitchen_square_df = None\n",
    "        self.house_year_rooms_square_df = None\n",
    "        self.house_year_rooms_life_square_df = None\n",
    "        self.district_social_df = None\n",
    "        self.district_healthcare_df = None\n",
    "        self.district_shops_df = None\n",
    "        self.house_floor_rooms_square_df = None\n",
    "        self.house_floor_rooms_life_square_df = None\n",
    "        \n",
    "\n",
    "    def add_square_av_meter_price(self, X):\n",
    "        temp = None\n",
    "        X['1Square'] = round(X['Square'] / 1)\n",
    "        if self.square_av_meter_price_df is None:\n",
    "            X['Price'] = self.y.values\n",
    "            X['MeterPrice'] = X['Price']/X['Square']\n",
    "            self.square_av_meter_price_df = X.groupby(['1Square'])['MeterPrice'].mean().reset_index()\\\n",
    "            .rename(columns = {'index':'1Square', 'MeterPrice':'SquareAvMeterPrice'})\n",
    "            X = X.drop(columns=['MeterPrice'])\n",
    "            X = X.drop(columns=['Price'])\n",
    "        X = X.merge(self.square_av_meter_price_df, on = ['1Square'], how = 'left')\n",
    "        X = X.drop(columns=['1Square'])\n",
    "        if (X['SquareAvMeterPrice'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['SquareAvMeterPrice'].median()\n",
    "            X.loc[X['SquareAvMeterPrice'].isnull(),'SquareAvMeterPrice'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_av_meter_price(self, X):\n",
    "        temp = None\n",
    "        if self.av_meter_price_df is None:\n",
    "            X['Price'] = self.y.values\n",
    "            X['MeterPrice'] = X['Price']/X['Square']\n",
    "            self.av_meter_price_df = X.groupby(['DistrictId'])['MeterPrice'].mean().reset_index()\\\n",
    "            .rename(columns = {'index':'DistrictId', 'MeterPrice':'AvMeterPrice'})\n",
    "            X = X.drop(columns=['MeterPrice'])\n",
    "            X = X.drop(columns=['Price'])\n",
    "        X = X.merge(self.av_meter_price_df, on = ['DistrictId'], how = 'left')\n",
    "        if (X['AvMeterPrice'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['AvMeterPrice'].median()\n",
    "            X.loc[X['AvMeterPrice'].isnull(),'AvMeterPrice'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_district_av_meter_price(self, X):\n",
    "        temp = None\n",
    "        if self.district_av_meter_price_df is None:\n",
    "            X['Price'] = self.y.values\n",
    "            self.district_av_meter_price_df = X.groupby('DistrictId')['Price'].mean().reset_index()\\\n",
    "            .rename(columns = {'index':'DistrictId'})\n",
    "            district_av_square = X.groupby('DistrictId')['Square'].mean().reset_index()\\\n",
    "            .rename(columns = {'index':'DistrictId'})\n",
    "            self.district_av_meter_price_df = self.district_av_meter_price_df.merge(district_av_square, on = 'DistrictId', how = 'left')\n",
    "            self.district_av_meter_price_df['DistrictAvMeterPrice'] = self.district_av_meter_price_df[\"Price\"]/self.district_av_meter_price_df[\"Square\"]\n",
    "            self.district_av_meter_price_df = self.district_av_meter_price_df.drop(['Price', 'Square'], axis = 1)\n",
    "            X = X.drop(columns=['Price'])\n",
    "        X = X.merge(self.district_av_meter_price_df, on='DistrictId', how='left')\n",
    "        if (X['DistrictAvMeterPrice'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['DistrictAvMeterPrice'].median()\n",
    "            X.loc[X['DistrictAvMeterPrice'].isnull(),'DistrictAvMeterPrice'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_district_house_floor_av_meter_price(self, X):\n",
    "        temp = None\n",
    "        if self.district_house_floor_av_meter_price_df is None:\n",
    "            X['Price'] = self.y.values\n",
    "            X['HouseFloorMeterPrice'] = X['Price']/X['HouseFloor']/X['Square']\n",
    "            self.district_house_floor_av_meter_price_df = X.groupby(['DistrictId', 'HouseFloor'])['HouseFloorMeterPrice'].median().reset_index()\\\n",
    "            .rename(columns = {'index':'DistrictId', 'HouseFloorMeterPrice':'DistrictHouseFloorAvMeterPrice'})\n",
    "            X = X.drop(columns=['Price'])\n",
    "            X = X.drop(columns=['HouseFloorMeterPrice'])\n",
    "        X = X.merge(self.district_house_floor_av_meter_price_df, on = ['DistrictId', 'HouseFloor'], how = 'left')\n",
    "        if (X['DistrictHouseFloorAvMeterPrice'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['DistrictHouseFloorAvMeterPrice'].median()\n",
    "            X.loc[X['DistrictHouseFloorAvMeterPrice'].isnull(),'DistrictHouseFloorAvMeterPrice'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_rooms_av_meter_price(self, X):\n",
    "        temp = None\n",
    "        if self.rooms_av_meter_price_df is None:\n",
    "            X['Price'] = self.y.values\n",
    "            X['RoomsMeterPrice'] = X['Price']/X['Square']\n",
    "            self.rooms_av_meter_price_df = X.groupby(['Rooms'])['RoomsMeterPrice'].mean().reset_index()\\\n",
    "            .rename(columns={'index':'Rooms', 'RoomsMeterPrice':'RoomsAvMeterPrice'})\n",
    "            X = X.drop(columns=['RoomsMeterPrice'])\n",
    "            X = X.drop(columns=['Price'])\n",
    "        X = X.merge(self.rooms_av_meter_price_df, on=['Rooms'], how='left')\n",
    "        if (X['RoomsAvMeterPrice'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['RoomsAvMeterPrice'].median()\n",
    "            X.loc[X['RoomsAvMeterPrice'].isnull(),'RoomsAvMeterPrice'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_district_rooms_av_meter_price(self, X):\n",
    "        if self.district_rooms_av_meter_price_df is None:\n",
    "            X['Price'] = self.y.values\n",
    "            X['RoomsMeterPrice'] = X['Price']/X['Square']\n",
    "            self.district_rooms_av_meter_price_df = X.groupby(['DistrictId','Rooms'])['RoomsMeterPrice'].median().reset_index()\\\n",
    "            .rename(columns={'index':'Rooms', 'RoomsMeterPrice':'DistrictRoomsAvMeterPrice'})\n",
    "            X = X.drop(columns=['RoomsMeterPrice'])\n",
    "            X = X.drop(columns=['Price'])\n",
    "        X = X.merge(self.district_rooms_av_meter_price_df, on=['DistrictId', 'Rooms'], how='left')\n",
    "        if (X['DistrictRoomsAvMeterPrice'].isnull().any()):\n",
    "            X.loc[X['DistrictRoomsAvMeterPrice'].isnull(),'DistrictRoomsAvMeterPrice'] = X.loc[X['DistrictRoomsAvMeterPrice'].isnull(),'RoomsAvMeterPrice']\n",
    "        return X\n",
    "    \n",
    "    def add_district_house_year_rooms_av_meter_price(self, X):\n",
    "        if self.district_house_year_rooms_av_meter_price_df is None:\n",
    "            X['Price'] = self.y.values\n",
    "            X['RoomsMeterPrice'] = X['Price']/X['Square']\n",
    "            self.district_house_year_rooms_av_meter_price_df = X.groupby(['DistrictId','Rooms', 'HouseYear'])['RoomsMeterPrice'].median().reset_index()\\\n",
    "            .rename(columns={'index':'Rooms', 'RoomsMeterPrice':'DistrictHouseYearRoomsAvMeterPrice'})\n",
    "            X = X.drop(columns=['RoomsMeterPrice'])\n",
    "            X = X.drop(columns=['Price'])\n",
    "        X = X.merge(self.district_house_year_rooms_av_meter_price_df, on=['DistrictId','Rooms', 'HouseYear'], how='left')\n",
    "        if (X['DistrictHouseYearRoomsAvMeterPrice'].isnull().any()):\n",
    "            X.loc[X['DistrictHouseYearRoomsAvMeterPrice'].isnull(),'DistrictHouseYearRoomsAvMeterPrice'] = X.loc[X['DistrictHouseYearRoomsAvMeterPrice'].isnull(),'DistrictHouseYearRoomsAvMeterPrice'].median()\n",
    "            X.loc[X['DistrictHouseYearRoomsAvMeterPrice'].isnull(),'DistrictHouseYearRoomsAvMeterPrice'] = X.loc[X['DistrictHouseYearRoomsAvMeterPrice'].isnull(),'DistrictRoomsAvMeterPrice']\n",
    "        return X\n",
    "    \n",
    "    def add_house_year_rooms_av_meter_price(self, X):\n",
    "        if self.house_year_rooms_av_meter_price_df is None:\n",
    "            X['Price'] = self.y.values\n",
    "            X['RoomsMeterPrice'] = X['Price']/X['Square']\n",
    "            self.house_year_rooms_av_meter_price_df = X.groupby(['Rooms', 'HouseYear'])['RoomsMeterPrice'].median().reset_index()\\\n",
    "            .rename(columns={'index':'Rooms', 'RoomsMeterPrice':'HouseYearRoomsAvMeterPrice'})\n",
    "            X = X.drop(columns=['RoomsMeterPrice'])\n",
    "            X = X.drop(columns=['Price'])\n",
    "        X = X.merge(self.house_year_rooms_av_meter_price_df, on=['Rooms', 'HouseYear'], how='left')\n",
    "        step = 6\n",
    "        for hyear in range(1900,2020):\n",
    "            if X.loc[(X['HouseYear'] == hyear), 'HouseYearRoomsAvMeterPrice'].isnull().any():\n",
    "                print('check')\n",
    "                wrongDataIndx = (X['HouseYear'] == hyear) & (X['HouseYearRoomsAvMeterPrice'].isnull())\n",
    "                corrDataIndx = (X['HouseYear'] >= hyear - step) & (X['HouseYear'] <= hyear + step)\n",
    "                X.loc[wrongDataIndx, 'HouseYearRoomsAvMeterPrice'] = X.loc[corrDataIndx, 'HouseYearRoomsAvMeterPrice'].median()\n",
    "            print(X.loc[(X['HouseYear'] >= hyear - step - 7) & (X['HouseYear'] <= hyear + step + 7), 'HouseYearRoomsAvMeterPrice'].median())\n",
    "            X.loc[(X['HouseYearRoomsAvMeterPrice'].isnull()), 'HouseYearRoomsAvMeterPrice'] = X.loc[(X['HouseYear'] >= hyear - step - 7) & (X['HouseYear'] <= hyear + step + 7), 'HouseYearRoomsAvMeterPrice'].median()\n",
    "        print(X.loc[(X['HouseYearRoomsAvMeterPrice'].isnull()),['HouseYearRoomsAvMeterPrice', 'HouseYear']])\n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def add_district_house_floor_rooms_av_meter_price(self, X):\n",
    "        if self.district_house_floor_rooms_av_meter_price_df is None:\n",
    "            X['Price'] = self.y.values\n",
    "            X['RoomsMeterPrice'] = X['Price']/X['Square']\n",
    "            self.district_house_floor_rooms_av_meter_price_df = X.groupby(['DistrictId','Rooms', 'HouseFloor'])['RoomsMeterPrice'].median().reset_index()\\\n",
    "            .rename(columns={'index':'Rooms', 'RoomsMeterPrice':'DistrictHouseFloorRoomsAvMeterPrice'})\n",
    "            X = X.drop(columns=['RoomsMeterPrice'])\n",
    "            X = X.drop(columns=['Price'])\n",
    "        X = X.merge(self.district_house_floor_rooms_av_meter_price_df, on=['DistrictId','Rooms', 'HouseFloor'], how='left')\n",
    "        if (X['DistrictHouseFloorRoomsAvMeterPrice'].isnull().any()):\n",
    "            X.loc[X['DistrictHouseFloorRoomsAvMeterPrice'].isnull(),'DistrictHouseFloorRoomsAvMeterPrice'] = X.loc[X['DistrictHouseFloorRoomsAvMeterPrice'].isnull(),'DistrictHouseFloorRoomsAvMeterPrice'].median()\n",
    "            X.loc[X['DistrictHouseFloorRoomsAvMeterPrice'].isnull(),'DistrictHouseFloorRoomsAvMeterPrice'] = X.loc[X['DistrictHouseFloorRoomsAvMeterPrice'].isnull(),'DistrictRoomsAvMeterPrice']\n",
    "        return X\n",
    "    \n",
    "    def add_district_kitchen_square_rooms_av_meter_price(self, X):\n",
    "        if self.district_kitchen_square_rooms_av_meter_price_df is None:\n",
    "            X['Price'] = self.y.values\n",
    "            X['RoomsMeterPrice'] = X['Price']/X['Square']\n",
    "            self.district_kitchen_square_rooms_av_meter_price_df = X.groupby(['DistrictId','Rooms', 'KitchenSquare'])['RoomsMeterPrice'].median().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'RoomsMeterPrice':'DistrictKitchenSquareRoomsAvMeterPrice'})\n",
    "            X = X.drop(columns=['RoomsMeterPrice'])\n",
    "            X = X.drop(columns=['Price'])\n",
    "        X = X.merge(self.district_kitchen_square_rooms_av_meter_price_df, on=['DistrictId','Rooms', 'KitchenSquare'], how='left')\n",
    "        if (X['DistrictKitchenSquareRoomsAvMeterPrice'].isnull().any()):\n",
    "            X.loc[X['DistrictKitchenSquareRoomsAvMeterPrice'].isnull(),'DistrictKitchenSquareRoomsAvMeterPrice'] = X['DistrictKitchenSquareRoomsAvMeterPrice'].median()\n",
    "        return X\n",
    "    \n",
    "    def add_district_life_square_rooms_av_meter_price(self, X):\n",
    "        if self.district_life_square_rooms_av_meter_price_df is None:\n",
    "            X['Price'] = self.y.values\n",
    "            X['RoomsMeterPrice'] = X['Price']/X['Square']\n",
    "            self.district_life_square_rooms_av_meter_price_df = X.groupby(['DistrictId','Rooms', 'LifeSquare'])['RoomsMeterPrice'].median().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'RoomsMeterPrice':'DistrictLifeSquareRoomsAvMeterPrice'})\n",
    "            X = X.drop(columns=['RoomsMeterPrice'])\n",
    "            X = X.drop(columns=['Price'])\n",
    "        X = X.merge(self.district_life_square_rooms_av_meter_price_df, on=['DistrictId','Rooms', 'LifeSquare'], how='left')\n",
    "        if (X['DistrictLifeSquareRoomsAvMeterPrice'].isnull().any()):\n",
    "            X.loc[X['DistrictLifeSquareRoomsAvMeterPrice'].isnull(),'DistrictLifeSquareRoomsAvMeterPrice'] = X['DistrictLifeSquareRoomsAvMeterPrice'].median()\n",
    "        return X\n",
    "    \n",
    "    def add_flat_av_meter_price(self, X):\n",
    "        if self.flat_av_meter_price_df is None:\n",
    "            X['Price'] = self.y.values\n",
    "            X['MeterPrice_1'] = X['Price']/X['Square'] # see add_av_meter_price\n",
    "            self.flat_av_meter_price_df = X.groupby(['DistrictId'])['MeterPrice_1'].mean().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'MeterPrice_1':'FlatAvMeterPrice'})\n",
    "            X = X.drop(columns=['MeterPrice_1'])\n",
    "            X = X.drop(columns=['Price'])\n",
    "        X = X.merge(self.flat_av_meter_price_df, on=['DistrictId'], how='left')\n",
    "        if (X['FlatAvMeterPrice'].isnull().any()):\n",
    "            X.loc[X['FlatAvMeterPrice'].isnull(),'FlatAvMeterPrice'] = X.loc[X['FlatAvMeterPrice'].isnull(),'RoomsAvMeterPrice']\n",
    "        return X\n",
    "    \n",
    "    def add_floor_meter_price(self, X):\n",
    "        temp = None\n",
    "        if self.floor_meter_price_df is None:\n",
    "            X['Price'] = self.y.values\n",
    "            X['FloorMeterPrice'] = X['Price']/X['Floor']/X['Square']\n",
    "            self.floor_meter_price_df = X.groupby(['DistrictId','Floor'])['FloorMeterPrice'].mean().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'FloorMeterPrice':'FloorAvMeterPrice'})\n",
    "            X = X.drop(columns=['FloorMeterPrice'])\n",
    "            X = X.drop(columns=['Price'])\n",
    "        X = X.merge(self.floor_meter_price_df, on=['DistrictId', 'Floor'], how='left')\n",
    "        if X['FloorAvMeterPrice'].isnull().any():\n",
    "            if temp is None:\n",
    "                temp = X['FloorAvMeterPrice'].median()\n",
    "            X.loc[X['FloorAvMeterPrice'].isnull(),'FloorAvMeterPrice'] = temp\n",
    "        return X\n",
    "    \n",
    "    # ____________________________________________\n",
    "    \n",
    "    def add_district_location(self, X):\n",
    "        temp = None\n",
    "        if self.district_location_df is None:\n",
    "            self.district_location_df = X.groupby('DistrictId')['HouseYear'].median().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'HouseYear':'DistrictLocation'})\n",
    "            self.district_location_df['DistrictLocation'] = self.district_location_df['DistrictLocation'].astype(int)\n",
    "        X = X.merge(self.district_location_df, on='DistrictId', how='left')\n",
    "        if (X['DistrictLocation'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['DistrictLocation'].median()\n",
    "            X.loc[X['DistrictLocation'].isnull(),'DistrictLocation'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_average_house_floor(self, X):\n",
    "        temp = None\n",
    "        if self.average_house_floor_df is None:\n",
    "            self.average_house_floor_df = X.groupby('DistrictId')['HouseFloor'].median().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'HouseFloor':'AvHouseFloor'})\n",
    "            self.average_house_floor_df['AvHouseFloor'] = self.average_house_floor_df['AvHouseFloor'].astype(int)\n",
    "        X = X.merge(self.average_house_floor_df, on='DistrictId', how='left')\n",
    "        if (X['AvHouseFloor'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['AvHouseFloor'].median()\n",
    "            X.loc[X['AvHouseFloor'].isnull(),'AvHouseFloor'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_number_of_flats(self, X):\n",
    "        temp = None\n",
    "        if self.number_of_flats_df is None:\n",
    "            self.number_of_flats_df = X['DistrictId'].value_counts().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'DistrictId':'NumberOfFlats'})\n",
    "        X = X.merge(self.number_of_flats_df, on='DistrictId', how='left')\n",
    "        if (X['NumberOfFlats'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['NumberOfFlats'].median()\n",
    "            X.loc[X['NumberOfFlats'].isnull(),'NumberOfFlats'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_mean_building_year(self, X):\n",
    "        # District have some new houses\n",
    "        temp = None\n",
    "        if self.mean_building_year_df is None:\n",
    "            self.mean_building_year_df = X.groupby('DistrictId')['HouseYear'].mean().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'HouseYear':'MeanBuildingYear'})\n",
    "            self.mean_building_year_df['MeanBuildingYear'] = self.mean_building_year_df['MeanBuildingYear'].astype(int)\n",
    "        X = X.merge(self.mean_building_year_df, on='DistrictId', how='left')\n",
    "        if (X['MeanBuildingYear'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['MeanBuildingYear'].median()\n",
    "            X.loc[X['MeanBuildingYear'].isnull(),'MeanBuildingYear'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_district_population(self, X):\n",
    "        # The more average rooms in flat the more people could leave in a house. The more sale announcements in district the more population in it.\n",
    "        temp = None\n",
    "        if self.district_population_df is None:\n",
    "            self.district_population_df = X.groupby('DistrictId')['Rooms'].mean().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId'})\n",
    "            number_of_flats = X['DistrictId'].value_counts().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'DistrictId':'NumberOfFlats'})\n",
    "            self.district_population_df = self.district_population_df.merge(number_of_flats, on='DistrictId', how='left')\n",
    "            self.district_population_df['DistrictAvPopulation'] = self.district_population_df[\"NumberOfFlats\"] / self.district_population_df[\"Rooms\"]\n",
    "            self.district_population_df = self.district_population_df.drop(['NumberOfFlats', 'Rooms'], axis = 1)\n",
    "        X = X.merge(self.district_population_df, on='DistrictId', how='left')\n",
    "        if (X['DistrictAvPopulation'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['DistrictAvPopulation'].median()\n",
    "            X.loc[X['DistrictAvPopulation'].isnull(),'DistrictAvPopulation'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_district_planting_of_greenery(self, X):\n",
    "        temp = None\n",
    "        if self.district_planting_of_greenery_df is None:\n",
    "            self.district_planting_of_greenery_df = X.groupby('DistrictId')['HouseFloor'].median().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'HouseFloor':'Greenery'})\n",
    "            self.district_planting_of_greenery_df['Greenery'] = self.district_planting_of_greenery_df['Greenery'].astype(int)\n",
    "        X = X.merge(self.district_planting_of_greenery_df, on='DistrictId', how='left')\n",
    "        if (X['Greenery'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['Greenery'].median()\n",
    "            X.loc[X['Greenery'].isnull(),'Greenery'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_ecology(self, X):\n",
    "        temp = None\n",
    "        X['Ecology'] = X['Ecology_1'] / max(X['Ecology_1']) * X['Ecology_2'] / max(X['Ecology_2']) * X['Ecology_3'] / max(X['Ecology_3'])\n",
    "        if self.ecology_df is None:\n",
    "            self.ecology_df = X.groupby('DistrictId')['Ecology'].median().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'Ecology':'DistrictAvEcology'})\n",
    "            #X = X.drop(columns=['Ecology'])\n",
    "        X = X.merge(self.ecology_df, on = 'DistrictId', how = 'left')\n",
    "        if (X['DistrictAvEcology'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['DistrictAvEcology'].median()\n",
    "            X.loc[X['DistrictAvEcology'].isnull(),'DistrictAvEcology'] = temp\n",
    "        temp = None\n",
    "        if (X['Ecology'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['Ecology'].median()\n",
    "            X.loc[X['Ecology'].isnull(),'Ecology'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_relative_house_floor(self, X):\n",
    "        temp = None\n",
    "        X['RelativeHouseFloor'] = X['Floor'] / X['HouseFloor']\n",
    "        X.loc[X['Floor'] == 1, 'RelativeHouseFloor'] = 0\n",
    "        return X\n",
    "    \n",
    "    def add_district_house_year_kitchen_square(self, X):\n",
    "        temp = None\n",
    "        if self.district_house_year_kitchen_square_df is None:\n",
    "            self.district_house_year_kitchen_square_df = X.groupby(['DistrictId', 'HouseYear'])['KitchenSquare'].median().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'KitchenSquare':'DistrHouseYearKitchenSquare'})\n",
    "        X = X.merge(self.district_house_year_kitchen_square_df, on = ['DistrictId', 'HouseYear'], how = 'left')\n",
    "        if (X['DistrHouseYearKitchenSquare'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X.groupby('DistrictId')['DistrHouseYearKitchenSquare'].median().reset_index()\n",
    "            for item in temp['DistrictId']:\n",
    "                X.loc[(X['DistrHouseYearKitchenSquare'].isnull()) & (X['DistrictId'] == item),'DistrHouseYearKitchenSquare'] = temp.loc[temp['DistrictId'] == item, 'DistrHouseYearKitchenSquare']\n",
    "            if (X['DistrHouseYearKitchenSquare'].isnull().any()):\n",
    "                X.loc[(X['DistrHouseYearKitchenSquare'].isnull()),'DistrHouseYearKitchenSquare'] = temp['DistrHouseYearKitchenSquare'].median()\n",
    "        return X\n",
    "    \n",
    "    def add_house_year_rooms_square(self, X):\n",
    "        temp = None\n",
    "        X['RoomsSq'] = X['Square'] / X['Rooms']\n",
    "        if self.house_year_rooms_square_df is None:\n",
    "            self.house_year_rooms_square_df = X.groupby(['HouseYear', 'Rooms'])['RoomsSq'].median().reset_index()\\\n",
    "            .rename(columns={'index':'HouseYear', 'RoomsSq':'HouseYearAvRoomSquare'})\n",
    "        X = X.drop(columns=['RoomsSq'])\n",
    "        X = X.merge(self.house_year_rooms_square_df, on = ['HouseYear', 'Rooms'], how = 'left')\n",
    "        if (X['HouseYearAvRoomSquare'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X.groupby('HouseYear')['HouseYearAvRoomSquare'].median().reset_index()\n",
    "            for item in temp['HouseYear']:\n",
    "                X.loc[(X['HouseYearAvRoomSquare'].isnull()) & (X['HouseYear'] == item),'HouseYearAvRoomSquare'] = temp.loc[temp['HouseYear'] == item, 'HouseYearAvRoomSquare']\n",
    "            if (X['HouseYearAvRoomSquare'].isnull().any()):\n",
    "                X.loc[(X['HouseYearAvRoomSquare'].isnull()),'HouseYearAvRoomSquare'] = temp['HouseYearAvRoomSquare'].median()\n",
    "        return X\n",
    "    \n",
    "    def add_house_year_rooms_lifesquare(self, X):\n",
    "        temp = None\n",
    "        X['RoomsLifeSquare'] = X['LifeSquare'] / X['Rooms']\n",
    "        if self.house_year_rooms_life_square_df is None:\n",
    "            self.house_year_rooms_life_square_df = X.groupby(['HouseYear', 'Rooms'])['RoomsLifeSquare'].median().reset_index()\\\n",
    "            .rename(columns={'index':'HouseYear', 'RoomsLifeSquare':'HouseYearAvRoomLifeSquare'})\n",
    "        X = X.drop(columns=['RoomsLifeSquare'])\n",
    "        X = X.merge(self.house_year_rooms_life_square_df, on = ['HouseYear', 'Rooms'], how = 'left')\n",
    "        if (X['HouseYearAvRoomLifeSquare'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X.groupby('HouseYear')['HouseYearAvRoomLifeSquare'].median().reset_index()\n",
    "            for item in temp['HouseYear']:\n",
    "                X.loc[(X['HouseYearAvRoomLifeSquare'].isnull()) & (X['HouseYear'] == item),'HouseYearAvRoomLifeSquare'] = temp.loc[temp['HouseYear'] == item, 'HouseYearAvRoomLifeSquare']\n",
    "            if (X['HouseYearAvRoomLifeSquare'].isnull().any()):\n",
    "                X.loc[(X['HouseYearAvRoomLifeSquare'].isnull()),'HouseYearAvRoomLifeSquare'] = temp['HouseYearAvRoomLifeSquare'].median()\n",
    "        return X\n",
    "    \n",
    "    def add_district_social(self, X):\n",
    "        temp = None\n",
    "        X['Social'] = X['Social_1'] / max(X['Social_1']) * X['Social_2'] / max(X['Social_2']) * X['Social_3'] / max(X['Social_3'])\n",
    "        if self.district_social_df is None:\n",
    "            self.district_social_df = X.groupby('DistrictId')['Social'].median().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'Social':'DistrictSocial'})\n",
    "        X = X.drop(columns=['Social'])\n",
    "        X = X.merge(self.district_social_df, on = 'DistrictId', how = 'left')\n",
    "        if (X['DistrictSocial'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['DistrictSocial'].median()\n",
    "                X.loc[(X['DistrictSocial'].isnull()),'DistrictSocial'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_district_healthcare(self, X):\n",
    "        temp = None\n",
    "        X['Healthcare'] = X['Healthcare_1'] / max(X['Healthcare_1']) * X['Helthcare_2'] / max(X['Helthcare_2'])\n",
    "        if self.district_healthcare_df is None:\n",
    "            self.district_healthcare_df = X.groupby('DistrictId')['Healthcare'].median().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'Healthcare':'DistrictHealthcare'})\n",
    "        X = X.drop(columns=['Healthcare'])\n",
    "        X = X.merge(self.district_healthcare_df, on = 'DistrictId', how = 'left')\n",
    "        if (X['DistrictSocial'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['DistrictHealthcare'].median()\n",
    "                X.loc[(X['DistrictHealthcare'].isnull()),'DistrictHealthcare'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_district_shops(self, X):\n",
    "        temp = None\n",
    "        X['Shops'] = X['Shops_1'] / max(X['Shops_1']) * X['Shops_2'] / max(X['Shops_2'])\n",
    "        if self.district_shops_df is None:\n",
    "            self.district_shops_df = X.groupby('DistrictId')['Shops'].median().reset_index()\\\n",
    "            .rename(columns={'index':'DistrictId', 'Shops':'DistrictShops'})\n",
    "        X = X.drop(columns=['Shops'])\n",
    "        X = X.merge(self.district_shops_df, on = 'DistrictId', how = 'left')\n",
    "        if (X['DistrictShops'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X['DistrictShops'].median()\n",
    "                X.loc[(X['DistrictShops'].isnull()),'DistrictShops'] = temp\n",
    "        return X\n",
    "    \n",
    "    def add_house_floor_rooms_square(self, X):\n",
    "        temp = None\n",
    "        X['RoomsSq'] = X['Square'] / X['Rooms']\n",
    "        if self.house_floor_rooms_square_df is None:\n",
    "            self.house_floor_rooms_square_df = X.groupby(['HouseFloor', 'Rooms'])['RoomsSq'].median().reset_index()\\\n",
    "            .rename(columns={'index':'HouseFloor', 'RoomsSq':'HouseFloorAvRoomSquare'})\n",
    "        X = X.drop(columns=['RoomsSq'])\n",
    "        X = X.merge(self.house_floor_rooms_square_df, on = ['HouseFloor', 'Rooms'], how = 'left')\n",
    "        if (X['HouseFloorAvRoomSquare'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X.groupby('HouseFloor')['HouseFloorAvRoomSquare'].median().reset_index()\n",
    "            for item in temp['HouseFloor']:\n",
    "                wrongdataindx = ((X['HouseFloorAvRoomSquare'].isnull()) & (X['HouseFloor'] == item))\n",
    "                X.loc[wrongdataindx,'HouseFloorAvRoomSquare'] = temp.loc[temp['HouseFloor'] == item, 'HouseFloorAvRoomSquare']\n",
    "            if (X['HouseFloorAvRoomSquare'].isnull().any()):\n",
    "                X.loc[(X['HouseFloorAvRoomSquare'].isnull()),'HouseFloorAvRoomSquare'] = temp['HouseFloorAvRoomSquare'].median()\n",
    "        return X\n",
    "    \n",
    "    def add_house_floor_rooms_lifesquare(self, X):\n",
    "        temp = None\n",
    "        X['RoomsLifeSquare'] = X['LifeSquare'] / X['Rooms']\n",
    "        if self.house_floor_rooms_life_square_df is None:\n",
    "            self.house_floor_rooms_life_square_df = X.groupby(['HouseFloor', 'Rooms'])['RoomsLifeSquare'].median().reset_index()\\\n",
    "            .rename(columns={'index':'HouseFloor', 'RoomsLifeSquare':'HouseFloorAvRoomLifeSquare'})\n",
    "        X = X.drop(columns=['RoomsLifeSquare'])\n",
    "        X = X.merge(self.house_floor_rooms_life_square_df, on = ['HouseFloor', 'Rooms'], how = 'left')\n",
    "        if (X['HouseFloorAvRoomLifeSquare'].isnull().any()):\n",
    "            if temp is None:\n",
    "                temp = X.groupby('HouseFloor')['HouseFloorAvRoomLifeSquare'].median().reset_index()\n",
    "            for item in temp['HouseFloor']:\n",
    "                X.loc[(X['HouseFloorAvRoomLifeSquare'].isnull()) & (X['HouseFloor'] == item),'HouseFloorAvRoomLifeSquare'] = temp.loc[temp['HouseFloor'] == item, 'HouseFloorAvRoomLifeSquare']\n",
    "            if (X['HouseFloorAvRoomLifeSquare'].isnull().any()):\n",
    "                X.loc[(X['HouseFloorAvRoomLifeSquare'].isnull()),'HouseFloorAvRoomLifeSquare'] = temp['HouseFloorAvRoomLifeSquare'].median()\n",
    "        return X\n",
    "    \n",
    "    def add_ideal_data(self, X):\n",
    "        temp = None\n",
    "        X['IdealData'] = X['WrongRooms'] + X['WrongSquare'] + X['WrongLifeSquare'] + X['WrongKitchenSquare'] + X['WrongHouseFloor'] + X['WrongFloor'] + X['WrongHouseYear'] + X['SingleRoom'] + X['WrongDistr']\n",
    "        return X\n",
    "    \n",
    "    def add_new_features(self, X):\n",
    "        if (self.y is not None):\n",
    "            X = self.add_square_av_meter_price(X)\n",
    "            X = self.add_av_meter_price(X)\n",
    "            X = self.add_district_av_meter_price(X)\n",
    "            X = self.add_district_house_floor_av_meter_price(X)\n",
    "            X = self.add_rooms_av_meter_price(X)\n",
    "            X = self.add_district_rooms_av_meter_price(X)\n",
    "            X = self.add_district_house_year_rooms_av_meter_price(X)\n",
    "            X = self.add_house_year_rooms_av_meter_price(X)\n",
    "            X = self.add_district_house_floor_rooms_av_meter_price(X)\n",
    "            X = self.add_district_kitchen_square_rooms_av_meter_price(X)\n",
    "            X = self.add_district_life_square_rooms_av_meter_price(X)\n",
    "            X = self.add_flat_av_meter_price(X)\n",
    "            X = self.add_floor_meter_price(X)\n",
    "        X = self.add_district_location(X)\n",
    "        X = self.add_average_house_floor(X)\n",
    "        X = self.add_number_of_flats(X)\n",
    "        X = self.add_mean_building_year(X)\n",
    "        X = self.add_district_population(X)\n",
    "        X = self.add_district_planting_of_greenery(X)\n",
    "        X = self.add_ecology(X)\n",
    "        X = self.add_relative_house_floor(X)\n",
    "        X = self.add_district_house_year_kitchen_square(X)\n",
    "        X = self.add_house_year_rooms_square(X)\n",
    "        X = self.add_house_year_rooms_lifesquare(X)\n",
    "        X = self.add_district_social(X)\n",
    "        X = self.add_district_healthcare(X)\n",
    "        X = self.add_district_shops(X)\n",
    "        X = self.add_house_floor_rooms_square(X)\n",
    "        X = self.add_house_floor_rooms_lifesquare(X)\n",
    "        X = self.add_ideal_data(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['DistrictId', 'Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',\n",
    "                 'Ecology_1', 'Social_1', 'Social_2', 'Social_3', 'Healthcare_1', 'Shops_1', 'WrongRooms']\n",
    "\n",
    "new_feature_names = ['SquareAvMeterPrice','AvMeterPrice','DistrictAvMeterPrice', 'DistrictHouseFloorAvMeterPrice',\n",
    "                     'DistrictRoomsAvMeterPrice', 'DistrictHouseYearRoomsAvMeterPrice', 'HouseYearRoomsAvMeterPrice',\n",
    "                     'DistrictHouseFloorRoomsAvMeterPrice', 'DistrictKitchenSquareRoomsAvMeterPrice',\n",
    "                     'DistrictLifeSquareRoomsAvMeterPrice', 'FlatAvMeterPrice', \n",
    "                     'FloorAvMeterPrice', 'DistrictLocation',\n",
    "                     'DistrictAvPopulation', 'Ecology', 'DistrictAvEcology', 'RelativeHouseFloor', \n",
    "                     'DistrHouseYearKitchenSquare', 'HouseYearAvRoomSquare', 'HouseYearAvRoomLifeSquare', \n",
    "                     'DistrictSocial', 'DistrictHealthcare', 'DistrictShops', 'HouseFloorAvRoomSquare', \n",
    "                     'IdealData']\n",
    "# full dataset\n",
    "\"\"\"feature_names = ['DistrictId', 'Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',\n",
    "                 'Ecology_1', 'Ecology_2', 'Ecology_3', 'Social_1', 'Social_2', 'Social_3', 'Healthcare_1',\n",
    "                 'Helthcare_2', 'Shops_1', 'Shops_2', 'WrongRooms', 'WrongSquare', 'WrongLifeSquare',\n",
    "                 'WrongKitchenSquare', 'WrongHouseFloor', 'WrongFloor', 'WrongHouseYear', 'SingleRoom', 'WrongDistr']\n",
    "new_feature_names = ['SquareAvMeterPrice','AvMeterPrice','DistrictAvMeterPrice', 'DistrictHouseFloorAvMeterPrice', \n",
    "                    'RoomsAvMeterPrice', \n",
    "                     'DistrictRoomsAvMeterPrice', 'DistrictHouseYearRoomsAvMeterPrice', 'HouseYearRoomsAvMeterPrice',\n",
    "                     'DistrictHouseFloorRoomsAvMeterPrice', 'DistrictKitchenSquareRoomsAvMeterPrice',\n",
    "                     'DistrictLifeSquareRoomsAvMeterPrice', 'FlatAvMeterPrice', \n",
    "                     'FloorAvMeterPrice', 'DistrictLocation', 'AvHouseFloor', 'NumberOfFlats', 'MeanBuildingYear', \n",
    "                     'DistrictAvPopulation', 'Greenery', 'Ecology', 'DistrictAvEcology', 'RelativeHouseFloor', \n",
    "                     'DistrHouseYearKitchenSquare', 'HouseYearAvRoomSquare', 'HouseYearAvRoomLifeSquare', \n",
    "                     'DistrictSocial', 'DistrictHealthcare', 'DistrictShops', 'HouseFloorAvRoomSquare', \n",
    "                     'HouseFloorAvRoomLifeSquare', 'IdealData'] \"\"\"\n",
    "target_name = 'Price'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train and set subdivision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "X = train.drop(columns = target_name)\n",
    "y = train[target_name]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.33, shuffle = True, random_state = 21)\n",
    "#print(X_train.shape, X_valid.shape, test.shape)\n",
    "train = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessing()\n",
    "X_train = preprocessor.data_correction(X_train)\n",
    "X_valid = preprocessor.data_correction(X_valid)\n",
    "test = preprocessor.data_correction(test)\n",
    "#print(X_train.shape, X_valid.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. New features add to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newfeatures = FeatureGeneration(y_train)\n",
    "print(X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = newfeatures.add_new_features(X_train)\n",
    "X_valid = newfeatures.add_new_features(X_valid)\n",
    "valid = X_valid.copy()\n",
    "test = newfeatures.add_new_features(test)\n",
    "X_train_initial, X_valid_initial, y_train_initial, y_valid_initial = X_train, X_valid, y_train, y_valid\n",
    "test_initial = test\n",
    "#X_train.shape, X_valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_initial[feature_names + new_feature_names]\n",
    "X_valid = X_valid_initial[feature_names + new_feature_names]\n",
    "test = test_initial[feature_names + new_feature_names]\n",
    "#X_train.shape, X_valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check NaN values through all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum().sum(), X_valid.isnull().sum().sum(), y_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.dtypes\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\n",
    "    print(\"Train R2:\\t\" + str(round(r2(train_true_values, train_pred_values), 3)))\n",
    "    print(\"Validation R2:\\t\" + str(round(r2(test_true_values, test_pred_values), 3)))\n",
    "    plt.figure(figsize = (18,10))\n",
    "    plt.subplot(121)\n",
    "    sns.scatterplot(x = train_pred_values, y = train_true_values)\n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('True values')\n",
    "    plt.title('Train sample prediction')\n",
    "    plt.subplot(122)\n",
    "    sns.scatterplot(x = test_pred_values, y = test_true_values)\n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('True values')\n",
    "    plt.title('Validation sample prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### rf_model = RandomForestRegressor(random_state = 21, criterion = 'mse')\n",
    "#n_estimators=100, *, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None\n",
    "rf_model = RandomForestRegressor(random_state = 21, n_estimators=300, criterion = 'mse', min_samples_leaf=3,\n",
    "                                 min_weight_fraction_leaf = 0.0005)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check NaN values through all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_valid.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = rf_model.predict(X_train)\n",
    "y_test_preds = rf_model.predict(X_valid)\n",
    "y_test_preds_rf = y_test_preds.copy()\n",
    "rf_model.score(X_valid, y_valid)\n",
    "evaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(rf_model, X_valid, y_valid, scoring = 'r2', cv = KFold(n_splits = 3, shuffle = True, random_state = 21))\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.922 #0.7593 random_state = 21, n_estimators=500, criterion = 'mse', max_depth = 14, min_samples_split=4, min_samples_leaf=3, min_weight_fraction_leaf = 0.00012\n",
    "0.927 #0.7594 random_state = 21, n_estimators=500, criterion = 'mse', max_depth = 16, min_samples_split=3, min_samples_leaf=3, min_weight_fraction_leaf = 0.0001\n",
    "0.927 #0.7594 random_state = 21, n_estimators=500, criterion = 'mse', max_depth = 16, min_samples_split=3, min_samples_leaf=3, min_weight_fraction_leaf = 0.00005\n",
    "0.911 #0.757 random_state = 21, n_estimators=600, criterion = 'mse', max_depth = 16, min_samples_split=3, min_samples_leaf=4, min_weight_fraction_leaf = 0.0001\n",
    "0.945 #0.7600 random_state = 21, n_estimators=600, criterion = 'mse', max_depth = 16, min_samples_split=2, min_samples_leaf=2, min_weight_fraction_leaf = 0.0001\n",
    "0.945 #0.760 random_state = 21, n_estimators=600, criterion = 'mse', max_depth = 16, min_samples_split=2, min_samples_leaf=2, min_weight_fraction_leaf = 0.0001\n",
    "0.946 #0.7595 random_state = 21, n_estimators=600, criterion = 'mse', max_depth = 16, min_samples_split=3, min_samples_leaf=2, min_weight_fraction_leaf = 0.0001\n",
    "0.923 #0.7590 random_state = 21, n_estimators=600, criterion = 'mse', max_depth = 12, min_samples_split=3, min_samples_leaf=2, min_weight_fraction_leaf = 0.0001\n",
    "0.939 #0.7598 random_state = 21, n_estimators=600, criterion = 'mse', max_depth = 14, min_samples_split=3, min_samples_leaf=2, min_weight_fraction_leaf = 0.0001\n",
    "0.939 #0.7613 random_state = 21, n_estimators=600, criterion = 'mse', max_depth = 14, min_samples_split=3, min_samples_leaf=2, min_weight_fraction_leaf = 0.0001\n",
    "0.939 #0.7615 random_state = 21, n_estimators=600, criterion = 'mse', max_depth = 15, min_samples_split=3, min_samples_leaf=2, min_weight_fraction_leaf = 0.0001\n",
    "0.929 #0.7600 random_state = 21, n_estimators=600, criterion = 'mse', max_depth = 16, min_samples_split=3, min_samples_leaf=3, min_weight_fraction_leaf = 0.00005\n",
    "cv_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(zip(X_train.columns, rf_model.feature_importances_), \n",
    "                                   columns = ['feature_name', 'importance'])\n",
    "\n",
    "feature_importances.sort_values(by = 'importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"(*, loss='ls', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', \n",
    "min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None, \n",
    "warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\"\"\"\n",
    "gb_model = GradientBoostingRegressor(loss='ls', learning_rate=0.01, n_estimators=300, subsample=1.0, \n",
    "                                     min_weight_fraction_leaf=0.0005, max_depth=12, max_features=18, random_state=21)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_preds = gb_model.predict(X_train)\n",
    "y_test_preds = gb_model.predict(X_valid)\n",
    "y_test_preds_gb = y_test_preds.copy()\n",
    "\n",
    "gb_model.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(gb_model, X_valid, y_valid, scoring = 'r2', cv = KFold(n_splits = 3, shuffle = True, random_state = 21))\n",
    "print(cv_score)\n",
    "0.7590 # loss='huber', learning_rate=0.02, n_estimators=500, subsample=1.0, min_samples_split=3, min_samples_leaf=5, min_weight_fraction_leaf=0.0001, max_depth=15, random_state=21, max_features=30\n",
    "0.976  # 0.7638 loss='huber', learning_rate=0.02, n_estimators=600, subsample=1.0, min_samples_split=5, min_samples_leaf=7, min_weight_fraction_leaf=0.0001, max_depth=15, random_state=21, max_features=30\n",
    "0.968 # 0.7635 loss='huber', learning_rate=0.023, n_estimators=300, subsample=1.0, min_samples_split=6, min_samples_leaf=8, min_weight_fraction_leaf=0.0001, max_depth=15, random_state=21, max_features=30\n",
    "0.969 # 0.7536 loss='huber', learning_rate=0.023, n_estimators=300, subsample=1.0, min_samples_split=6, min_samples_leaf=8, min_weight_fraction_leaf=0.0001, max_depth=15, random_state=21, max_features=40\n",
    "0.969 # 0.7616 loss='huber', learning_rate=0.023, n_estimators=300, subsample=1.0, min_samples_split=6, min_samples_leaf=8, min_weight_fraction_leaf=0.0001, max_depth=15, random_state=21, max_features=35\n",
    "0.97 #0.7503 loss='huber', learning_rate=0.025, n_estimators=300, subsample=1.0, min_samples_split=6, min_samples_leaf=8, min_weight_fraction_leaf=0.00005, max_depth=16, random_state=21\n",
    "0.969 #0.7685 loss='huber', learning_rate=0.025, n_estimators=300, subsample=1.0, min_samples_split=6, min_samples_leaf=8, min_weight_fraction_leaf=0.00005, max_depth=16, random_state=21, max_features=20\n",
    "0.968 # 0.7690 loss='huber', learning_rate=0.025, n_estimators=300, subsample=1.0, min_samples_split=6, min_samples_leaf=8, min_weight_fraction_leaf=0.00005, max_depth=16, random_state=21, max_features=15\n",
    "0.968 # 0.7690 loss='huber', learning_rate=0.025, n_estimators=300, subsample=1.0, min_samples_split=6, min_samples_leaf=8, min_weight_fraction_leaf=0.00005, max_depth=16, random_state=21, max_features=20\n",
    "0.971 #0.7674 loss='huber', learning_rate=0.025, n_estimators=300, subsample=1.0, min_samples_split=6, min_samples_leaf=8, min_weight_fraction_leaf=0.00005, max_depth=16, random_state=21, max_features=20\n",
    "0.976 #0.7659 loss='huber', learning_rate=0.025, n_estimators=300, subsample=1.0, min_samples_split=4, min_samples_leaf=5, min_weight_fraction_leaf=0.0001, max_depth=12, random_state=21, max_features=15\n",
    "0.982 #0.7617 loss='huber', learning_rate=0.025, n_estimators=300, subsample=1.0, min_samples_split=4, min_samples_leaf=5, min_weight_fraction_leaf=0.00005, max_depth=14, random_state=21, max_features=15\n",
    "0.984 #0.7643 loss='huber', learning_rate=0.025, n_estimators=300, subsample=1.0, min_samples_split=4, min_samples_leaf=5, min_weight_fraction_leaf=0.00005, max_depth=14, random_state=21, max_features=15\n",
    "0.975 #0.7729 loss='huber', learning_rate=0.023, n_estimators=400, subsample=1.0, min_samples_split=6, min_samples_leaf=8, min_weight_fraction_leaf=0.00005, max_depth=16, random_state=21, max_features=22\n",
    "\n",
    "cv_score.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(zip(X_train.columns, gb_model.feature_importances_), \n",
    "                                   columns = ['feature_name', 'importance'])\n",
    "feature_importances.sort_values(by = 'importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"(base_estimator=None, n_estimators=10, *, max_samples=1.0, max_features=1.0, bootstrap=True, \n",
    "bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0)\"\"\"\n",
    "bagg_model = BaggingRegressor(n_estimators = 300 , random_state = 21)\n",
    "bagg_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_preds = bagg_model.predict(X_train)\n",
    "y_test_preds = bagg_model.predict(X_valid)\n",
    "y_test_preds_bagg = y_test_preds.copy()\n",
    "\n",
    "bagg_model.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(bagg_model, X_valid, y_valid, scoring = 'r2', cv = KFold(n_splits = 3, shuffle = True, random_state = 21))\n",
    "print(cv_score)\n",
    "cv_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"(loss='least_squares', *, learning_rate=0.1, max_iter=100, max_leaf_nodes=31, max_depth=None, \n",
    "min_samples_leaf=20, l2_regularization=0.0, max_bins=255, categorical_features=None, monotonic_cst=None, \n",
    "warm_start=False, early_stopping='auto', scoring='loss', validation_fraction=0.1, n_iter_no_change=10, tol=1e-07, \n",
    "verbose=0, random_state=None)\"\"\"\n",
    "histgb_model = HistGradientBoostingRegressor(loss='least_squares', max_iter = 400,max_leaf_nodes=30, \n",
    "                                             max_depth=16, min_samples_leaf=5, random_state=21)\n",
    "histgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_preds = histgb_model.predict(X_train)\n",
    "y_test_preds = histgb_model.predict(X_valid)\n",
    "y_test_preds_histgb = y_test_preds.copy()\n",
    "\n",
    "histgb_model.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv_score = cross_val_score(bagg_model, X_valid, y_valid, scoring = 'r2', cv = KFold(n_splits = 3, shuffle = True, random_state = 21))\n",
    "print(cv_score)\n",
    "cv_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_importances = pd.DataFrame(zip(X_train.columns, gb_model.feature_importances_), \n",
    "                                   columns = ['feature_name', 'importance'])\n",
    "feature_importances.sort_values(by = 'importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votingregr = VotingRegressor([('rf_model', rf_model), ('gb_model', gb_model), ('bagg_model', bagg_model)], n_jobs = -1)\n",
    "votingregr.fit(X_train, y_train)\n",
    "y_train_preds = votingregr.predict(X_train)\n",
    "y_test_preds = votingregr.predict(X_valid)\n",
    "y_test_preds_vr = y_test_preds.copy()\n",
    "\n",
    "evaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(votingregr, X_valid, y_valid, scoring = 'r2', cv = KFold(n_splits = 3, shuffle = True, random_state = 21))\n",
    "print(cv_score)\n",
    "cv_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_preds_vr\n",
    "y_test_preds_bagg\n",
    "y_test_preds_gb\n",
    "y_test_preds_rf\n",
    "frame = { 'Price': y_valid_initial, 'PredPrice': y_test_preds_rf } \n",
    "temp = pd.DataFrame(frame)\n",
    "temp['WrongPrice'] = 0.0\n",
    "temp.loc[(abs(temp['Price'] - temp['PredPrice'])/temp['Price'])>0.25,'WrongPrice'] = 1\n",
    "#print(temp.columns.tolist())\n",
    "valid['Price'] = y_valid_initial.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (9,10))\n",
    "sns.scatterplot(x = temp.loc[temp['WrongPrice'] == 1, 'Price'], y = temp.loc[temp['WrongPrice'] == 1, 'PredPrice'])\n",
    "temp.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns1 = ['Id','DistrictId', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',\n",
    "#                 'IdealData', 'WrongHouseYear' , 'WrongHouseFloor' , 'WrongFloor' , 'WrongRoom' , 'WrongSquare' , 'WrongLifeSquare' , 'WrongKitchenSquare']\n",
    "if 'PredPrice' in valid.columns:\n",
    "    valid = valid.drop(columns=['PredPrice', 'WrongPrice'])\n",
    "    \n",
    "valid = valid.merge(temp, on = 'Price',how = 'left')\n",
    "valid.columns.tolist()\n",
    "#valid.loc[valid['Price'] != 1, columns1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "columns1 = ['DistrictId', 'Square', 'Rooms', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',\n",
    "                   'Price', 'PredPrice']\n",
    "wrongdataindx = (valid['WrongPrice'] == 1) & (valid['HouseYear'] >= 1920) & (valid['HouseYear'] <= 2020)\n",
    "corrdataindx = (valid['WrongPrice'] != 1)\n",
    "print('overall wrong price: ', valid.loc[wrongdataindx, 'DistrictId'].count())\n",
    "print('corrected data', '\\n',valid.loc[wrongdataindx & (valid['IdealData'] != 0), 'HouseYear'].count())\n",
    "print('WrongHouseYear ', '\\n', valid.loc[wrongdataindx & (valid['WrongHouseYear'] != 0), 'HouseYear'].count())\n",
    "print('WrongHouseFloor ', '\\n', valid.loc[wrongdataindx & (valid['WrongHouseFloor'] != 0), 'HouseYear'].count())\n",
    "print('WrongFloor ', '\\n', valid.loc[wrongdataindx & (valid['WrongFloor'] != 0), 'HouseYear'].count())\n",
    "print('WrongRooms ', '\\n', valid.loc[wrongdataindx & (valid['WrongRooms'] != 0), 'HouseYear'].count())\n",
    "print('WrongKitchenSquare ', '\\n', valid.loc[wrongdataindx & (valid['WrongKitchenSquare'] != 0), 'HouseYear'].count())\n",
    "print('WrongSquare ', '\\n', valid.loc[wrongdataindx & (valid['Square'] > 120), 'HouseYear'].count())\n",
    "print('WrongLifeSquare ', '\\n', valid.loc[wrongdataindx & (valid['WrongLifeSquare'] != 0), 'HouseYear'].count())\n",
    "print('overall correct price: ', valid.loc[corrdataindx, 'DistrictId'].count())\n",
    "print('corrected data', '\\n',valid.loc[corrdataindx & (valid['IdealData'] != 0), 'HouseYear'].count())\n",
    "print('WrongHouseYear ', '\\n', valid.loc[corrdataindx & (valid['WrongHouseYear'] != 0), 'HouseYear'].count())\n",
    "print('WrongHouseFloor ', '\\n', valid.loc[corrdataindx & (valid['WrongHouseFloor'] != 0), 'HouseYear'].count())\n",
    "print('WrongFloor ', '\\n', valid.loc[corrdataindx & (valid['WrongFloor'] != 0), 'HouseYear'].count())\n",
    "print('WrongRooms ', '\\n', valid.loc[corrdataindx & (valid['WrongRooms'] != 0), 'HouseYear'].count())\n",
    "print('WrongKitchenSquare ', '\\n', valid.loc[corrdataindx & (valid['WrongKitchenSquare'] != 0), 'HouseYear'].count())\n",
    "print('WrongSquare ', '\\n', valid.loc[corrdataindx & (valid['WrongSquare'] != 0), 'HouseYear'].count())\n",
    "print('WrongLifeSquare ', '\\n', valid.loc[corrdataindx & (valid['WrongLifeSquare'] != 0), 'HouseYear'].count())\n",
    "\n",
    "\n",
    "print(valid.loc[(valid['WrongPrice'] == 1) & (valid['LifeSquare'] <= 90), 'DistrictId'].count())\n",
    "\n",
    "print(valid.loc[(valid['WrongPrice'] == 1) & (valid['WrongHouseFloor'] == 0), 'DistrictId'].count(), valid.loc[valid['WrongFloor'] == 0, 'DistrictId'].count())\n",
    "print(valid.loc[(valid['WrongPrice'] == 1) & (valid['HouseYear'] == 1977), 'DistrictId'].count(), valid.loc[(valid['WrongPrice'] != 1) & (valid['HouseYear'] == 1977), 'DistrictId'].count())\n",
    "print(valid.loc[(valid['WrongPrice'] == 1) & (valid['HouseYear'] == 1989), 'DistrictId'].count(), valid.loc[(valid['WrongPrice'] != 1) & (valid['HouseYear'] == 1989), 'DistrictId'].count())\n",
    "\n",
    "valid.loc[(valid['WrongPrice'] != 0)].head(10)\n",
    "wrongdataindx = (valid['WrongPrice'] != 0) & (valid['WrongHouseFloor'] != 0) & (valid['HouseYear'] >= 1920) & (valid['HouseYear'] <= 2020)\n",
    "plt.hist(valid.loc[wrongdataindx, 'HouseYear'], bins = 2020-1920, range = (1920, 2020))\n",
    "plt.title('HouseYear')\n",
    "plt.show()\n",
    "plt.hist(valid.loc[wrongdataindx, 'Floor'], bins = 20-1, range = (1, 20))\n",
    "plt.title('Floor')\n",
    "plt.show()\n",
    "plt.hist(valid.loc[wrongdataindx, 'HouseFloor'], bins = 26-1, range = (1, 26))\n",
    "plt.title('HouseFloor')\n",
    "plt.show()\n",
    "plt.hist(valid.loc[wrongdataindx, 'LifeSquare'], bins = 70-10, range = (10, 70))\n",
    "plt.title('LifeSquare')\n",
    "plt.show()\n",
    "plt.hist(valid.loc[wrongdataindx, 'Square'], bins = 100-25, range = (25, 100))\n",
    "plt.title('Square')\n",
    "plt.show()\n",
    "plt.hist(valid.loc[wrongdataindx, 'KitchenSquare'], bins = 15-5, range = (5, 15))\n",
    "plt.title('KitchenSquare')\n",
    "plt.show()\n",
    "plt.hist(valid.loc[wrongdataindx, 'Rooms'], bins = 6-1, range = (1, 6))\n",
    "plt.title('Rooms')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (14,10))\n",
    "wrongDataIndx = (valid['WrongPrice'] != 0) & (valid['WrongHouseFloor'] != 0)\n",
    "sns.scatterplot(x = valid.loc[wrongDataIndx, 'HouseYear'], y = valid.loc[wrongDataIndx, 'DistrictId'])\n",
    "plt.grid(b = True, which = 'both')\n",
    "plt.minorticks_on\n",
    "plt.show()\n",
    "\n",
    "valid.loc[(valid['WrongPrice'] == 1) & (valid['WrongHouseYear'] != 0), columns1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid = valid.drop(columns = ['bad'])\n",
    "valid['bad'] = abs((valid['Price'] - valid['PredPrice']) / valid['Price'])\n",
    "valid['bad'].max(), valid['bad'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7167"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('rf_model', rf_model), ('gb_model', gb_model), ('bagg_model', bagg_model), ('histgb_model', histgb_model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"stack_model = StackingRegressor(estimators=estimators)\n",
    "stack_model.fit(X_train, y_train)\n",
    "y_train_preds = stack_model.predict(X_train)\n",
    "y_test_preds = stack_model.predict(X_valid)\n",
    "stack_model.score(X_valid, y_valid)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"evaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"cv_score = cross_val_score(votingregr, X_valid, y_valid, scoring = 'r2', cv = KFold(n_splits = 3, shuffle = True, random_state = 21))\n",
    "print(cv_score)\n",
    "cv_score.mean()\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
